{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12370997",
   "metadata": {},
   "source": [
    "# 1. Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ece6f4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.11/site-packages (25.0.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.0.1\n",
      "    Uninstalling pip-25.0.1:\n",
      "      Successfully uninstalled pip-25.0.1\n",
      "Successfully installed pip-25.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting llmcompressor\n",
      "  Downloading llmcompressor-0.9.0.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: loguru<=0.7.3,>=0.7.2 in /opt/conda/lib/python3.11/site-packages (from llmcompressor) (0.7.3)\n",
      "Requirement already satisfied: pyyaml<=6.0.3,>=6.0.1 in /opt/conda/lib/python3.11/site-packages (from llmcompressor) (6.0.2)\n",
      "Requirement already satisfied: numpy<=2.3.5,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from llmcompressor) (2.2.5)\n",
      "Requirement already satisfied: requests<=2.32.5,>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from llmcompressor) (2.32.3)\n",
      "Requirement already satisfied: tqdm<=4.67.1,>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from llmcompressor) (4.67.1)\n",
      "Requirement already satisfied: torch<=2.9.1,>=2.7.0 in /opt/conda/lib/python3.11/site-packages (from llmcompressor) (2.9.1)\n",
      "Collecting transformers<=4.57.3,>=4.54.0 (from llmcompressor)\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting datasets<=4.4.1,>=4.0.0 (from llmcompressor)\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: accelerate<=1.12.0,>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from llmcompressor) (1.12.0)\n",
      "Collecting nvidia-ml-py<=13.590.44,>=12.560.30 (from llmcompressor)\n",
      "  Downloading nvidia_ml_py-13.590.44-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: pillow<=12.0.0,>=10.4.0 in /opt/conda/lib/python3.11/site-packages (from llmcompressor) (11.0.0)\n",
      "Requirement already satisfied: compressed-tensors==0.13.0 in /opt/conda/lib/python3.11/site-packages (from llmcompressor) (0.13.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.11/site-packages (from compressed-tensors==0.13.0->llmcompressor) (2.12.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate<=1.12.0,>=1.6.0->llmcompressor) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate<=1.12.0,>=1.6.0->llmcompressor) (7.0.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate<=1.12.0,>=1.6.0->llmcompressor) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate<=1.12.0,>=1.6.0->llmcompressor) (0.7.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets<=4.4.1,>=4.0.0->llmcompressor) (3.18.0)\n",
      "Collecting pyarrow>=21.0.0 (from datasets<=4.4.1,>=4.0.0->llmcompressor)\n",
      "  Downloading pyarrow-23.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets<=4.4.1,>=4.0.0->llmcompressor)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets<=4.4.1,>=4.0.0->llmcompressor)\n",
      "  Downloading pandas-3.0.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets<=4.4.1,>=4.0.0->llmcompressor) (0.28.1)\n",
      "Collecting xxhash (from datasets<=4.4.1,>=4.0.0->llmcompressor)\n",
      "  Downloading xxhash-3.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets<=4.4.1,>=4.0.0->llmcompressor)\n",
      "  Downloading multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets<=4.4.1,>=4.0.0->llmcompressor) (2025.3.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets<=4.4.1,>=4.0.0->llmcompressor) (3.13.3)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.11/site-packages (from httpx<1.0.0->datasets<=4.4.1,>=4.0.0->llmcompressor) (4.12.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1.0.0->datasets<=4.4.1,>=4.0.0->llmcompressor) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1.0.0->datasets<=4.4.1,>=4.0.0->llmcompressor) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.11/site-packages (from httpx<1.0.0->datasets<=4.4.1,>=4.0.0->llmcompressor) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0.0->datasets<=4.4.1,>=4.0.0->llmcompressor) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate<=1.12.0,>=1.6.0->llmcompressor) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate<=1.12.0,>=1.6.0->llmcompressor) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<=2.32.5,>=2.32.2->llmcompressor) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<=2.32.5,>=2.32.2->llmcompressor) (2.3.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /opt/conda/lib/python3.11/site-packages (from torch<=2.9.1,>=2.7.0->llmcompressor) (3.5.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers<=4.57.3,>=4.54.0->llmcompressor) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.11/site-packages (from transformers<=4.57.3,>=4.54.0->llmcompressor) (0.22.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets<=4.4.1,>=4.0.0->llmcompressor) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets<=4.4.1,>=4.0.0->llmcompressor) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets<=4.4.1,>=4.0.0->llmcompressor) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets<=4.4.1,>=4.0.0->llmcompressor) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets<=4.4.1,>=4.0.0->llmcompressor) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets<=4.4.1,>=4.0.0->llmcompressor) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets<=4.4.1,>=4.0.0->llmcompressor) (1.22.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.0->compressed-tensors==0.13.0->llmcompressor) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.0->compressed-tensors==0.13.0->llmcompressor) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.0->compressed-tensors==0.13.0->llmcompressor) (0.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch<=2.9.1,>=2.7.0->llmcompressor) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch<=2.9.1,>=2.7.0->llmcompressor) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets<=4.4.1,>=4.0.0->llmcompressor) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets<=4.4.1,>=4.0.0->llmcompressor) (1.17.0)\n",
      "Downloading llmcompressor-0.9.0.1-py3-none-any.whl (282 kB)\n",
      "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading multiprocess-0.70.18-py311-none-any.whl (144 kB)\n",
      "Downloading nvidia_ml_py-13.590.44-py3-none-any.whl (50 kB)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-23.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.5/47.5 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-3.0.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Installing collected packages: nvidia-ml-py, xxhash, pyarrow, dill, pandas, multiprocess, transformers, datasets, llmcompressor\n",
      "\u001b[2K  Attempting uninstall: nvidia-ml-py\n",
      "\u001b[2K    Found existing installation: nvidia-ml-py 13.590.48\n",
      "\u001b[2K    Uninstalling nvidia-ml-py-13.590.48:\n",
      "\u001b[2K      Successfully uninstalled nvidia-ml-py-13.590.48\u001b[32m0/9\u001b[0m [nvidia-ml-py]\n",
      "\u001b[2K  Attempting uninstall: dill0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/9\u001b[0m [pyarrow]\n",
      "\u001b[2K    Found existing installation: dill 0.4.1━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/9\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling dill-0.4.1:0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/9\u001b[0m [dill]\n",
      "\u001b[2K      Successfully uninstalled dill-0.4.1━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/9\u001b[0m [dill]\n",
      "\u001b[2K  Attempting uninstall: transformers90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/9\u001b[0m [multiprocess]\n",
      "\u001b[2K    Found existing installation: transformers 4.57.6━━━━━━━━━━\u001b[0m \u001b[32m5/9\u001b[0m [multiprocess]\n",
      "\u001b[2K    Uninstalling transformers-4.57.6:m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m6/9\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.57.6━━━━━━━━━━━━\u001b[0m \u001b[32m6/9\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9/9\u001b[0m [llmcompressor]0m [llmcompressor]\n",
      "\u001b[1A\u001b[2KSuccessfully installed datasets-4.4.1 dill-0.4.0 llmcompressor-0.9.0.1 multiprocess-0.70.18 nvidia-ml-py-13.590.44 pandas-3.0.0 pyarrow-23.0.0 transformers-4.57.3 xxhash-3.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install llmcompressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3461c070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.11/site-packages (8.1.8)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (9.1.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.15.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/conda/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f90c1891d44000b716079e705c75c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "!pip install ipywidgets\n",
    "\n",
    "login()     # Your huggingface access token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f7f3c5",
   "metadata": {},
   "source": [
    "# 2. Compress Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795a3356",
   "metadata": {},
   "source": [
    "## 2.1. Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062fa194",
   "metadata": {},
   "source": [
    "See [Quantization Schemes](https://docs.vllm.ai/projects/llm-compressor/en/0.8.1/guides/compression_schemes/) for choosing quantization method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff607ea",
   "metadata": {},
   "source": [
    "EX1). `INT W8A8` quantization with SmoothQuant and GPTQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a903a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmcompressor.modifiers.smoothquant import SmoothQuantModifier\n",
    "from llmcompressor.modifiers.quantization import GPTQModifier\n",
    "from llmcompressor import oneshot\n",
    "\n",
    "\n",
    "recipe = [\n",
    "    SmoothQuantModifier(smoothing_strength=0.8),\n",
    "    GPTQModifier(scheme=\"W8A8\", targets=\"Linear\", ignore=[\"lm_head\"]),\n",
    "]\n",
    "\n",
    "\n",
    "SAVE_DIR=\"TinyLlama-1.1B-Chat-v1.0-INT8\"\n",
    "\n",
    "oneshot(\n",
    "    model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    dataset=\"open_platypus\",\n",
    "    recipe=recipe,\n",
    "    output_dir=SAVE_DIR,\n",
    "    max_seq_length=2048,\n",
    "    num_calibration_samples=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241dfbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 01-23 05:25:10 [utils.py:263] non-default args: {'gpu_memory_utilization': 0.7, 'disable_log_stats': True, 'model': './TinyLlama-1.1B-Chat-v1.0-INT8'}\n",
      "INFO 01-23 05:25:10 [model.py:530] Resolved architecture: LlamaForCausalLM\n",
      "INFO 01-23 05:25:10 [model.py:1545] Using max model len 2048\n",
      "INFO 01-23 05:25:12 [scheduler.py:229] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 01-23 05:25:12 [vllm.py:630] Asynchronous scheduling is enabled.\n",
      "INFO 01-23 05:25:12 [vllm.py:637] Disabling NCCL for DP synchronization when using async scheduling.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=166254)\u001b[0;0m INFO 01-23 05:25:12 [core.py:97] Initializing a V1 LLM engine (v0.14.0) with config: model='./TinyLlama-1.1B-Chat-v1.0-INT8', speculative_config=None, tokenizer='./TinyLlama-1.1B-Chat-v1.0-INT8', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=compressed-tensors, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=0, served_model_name=./TinyLlama-1.1B-Chat-v1.0-INT8, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [8192], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 512, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}\n",
      "\u001b[0;36m(EngineCore_DP0 pid=166254)\u001b[0;0m INFO 01-23 05:25:12 [parallel_state.py:1214] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://172.17.0.3:58591 backend=nccl\n",
      "\u001b[0;36m(EngineCore_DP0 pid=166254)\u001b[0;0m INFO 01-23 05:25:12 [parallel_state.py:1425] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank N/A\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "\u001b[0;36m(EngineCore_DP0 pid=166254)\u001b[0;0m INFO 01-23 05:25:12 [gpu_model_runner.py:3808] Starting to load model ./TinyLlama-1.1B-Chat-v1.0-INT8...\n",
      "\u001b[0;36m(EngineCore_DP0 pid=166254)\u001b[0;0m INFO 01-23 05:25:13 [compressed_tensors_w8a8_int8.py:62] Using CutlassScaledMMLinearKernel for CompressedTensorsW8A8Int8\n",
      "\u001b[0;36m(EngineCore_DP0 pid=166254)\u001b[0;0m INFO 01-23 05:25:13 [cuda.py:351] Using FLASH_ATTN attention backend out of potential backends: ('FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fa7f27458549f08503ad1fb5ca5fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=166254)\u001b[0;0m INFO 01-23 05:25:13 [default_loader.py:291] Loading weights took 0.20 seconds\n",
      "\u001b[0;36m(EngineCore_DP0 pid=166254)\u001b[0;0m INFO 01-23 05:25:14 [gpu_model_runner.py:3905] Model loading took 1.15 GiB memory and 0.463936 seconds\n",
      "\u001b[0;36m(EngineCore_DP0 pid=166254)\u001b[0;0m INFO 01-23 05:25:18 [backends.py:644] Using cache directory: /root/.cache/vllm/torch_compile_cache/c0332d605c/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[0;36m(EngineCore_DP0 pid=166254)\u001b[0;0m INFO 01-23 05:25:18 [backends.py:704] Dynamo bytecode transform time: 4.53 s\n",
      "\u001b[0;36m(EngineCore_DP0 pid=166254)\u001b[0;0m INFO 01-23 05:25:20 [backends.py:226] Directly load the compiled graph(s) for compile range (1, 8192) from the cache, took 0.332 s\n",
      "\u001b[0;36m(EngineCore_DP0 pid=166254)\u001b[0;0m INFO 01-23 05:25:20 [monitor.py:34] torch.compile takes 4.86 s in total\n",
      "\u001b[0;36m(EngineCore_DP0 pid=166254)\u001b[0;0m INFO 01-23 05:25:21 [gpu_worker.py:358] Available KV cache memory: 14.92 GiB\n",
      "\u001b[0;36m(EngineCore_DP0 pid=166254)\u001b[0;0m INFO 01-23 05:25:21 [kv_cache_utils.py:1305] GPU KV cache size: 711,008 tokens\n",
      "\u001b[0;36m(EngineCore_DP0 pid=166254)\u001b[0;0m INFO 01-23 05:25:21 [kv_cache_utils.py:1310] Maximum concurrency for 2,048 tokens per request: 347.17x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:00<00:00, 55.67it/s]\n",
      "Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:00<00:00, 54.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=166254)\u001b[0;0m INFO 01-23 05:25:23 [gpu_model_runner.py:4856] Graph capturing finished in 2 secs, took 0.44 GiB\n",
      "\u001b[0;36m(EngineCore_DP0 pid=166254)\u001b[0;0m INFO 01-23 05:25:23 [core.py:273] init engine (profile, create kv cache, warmup model) took 9.93 seconds\n",
      "INFO 01-23 05:25:24 [llm.py:347] Supported tasks: ['generate']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5121e575a048159a50b4918b0e00db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbebe35ff5b4b79bd18b5533df9c2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. And Pikachu is yellow and Google is red\n",
      "\n",
      "So yes, those are some great questions and they present opportunities for social storytelling.\n"
     ]
    }
   ],
   "source": [
    "# Inference quantized model via vLLM\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "\n",
    "model_path = \"./TinyLlama-1.1B-Chat-v1.0-INT8\"\n",
    "# model_path = SAVE_DIR\n",
    "\n",
    "model = LLM(\n",
    "    model=model_path,    \n",
    "    gpu_memory_utilization=0.7, # GPU 메모리 70% 사용 (필요시 조절)\n",
    "    tensor_parallel_size=1,   # GPU 1개 사용\n",
    "    # enforce_eager=True      # 호환성 모드 켜기 (필요시)\n",
    ")\n",
    "\n",
    "sampling_params = SamplingParams(max_tokens=256)\n",
    "\n",
    "outputs = model.generate(\"Sky is blue and Apple is \", sampling_params)\n",
    "\n",
    "for output in outputs:\n",
    "    print(\"Answer: \", output.outputs[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9cbab4",
   "metadata": {},
   "source": [
    "결과: 2.2Gb -> 1.15Gb로 원본대비 약 52% 압축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04126182",
   "metadata": {},
   "source": [
    "EX2). `INT W8A8` quantization with AWQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33271450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0fcfe4c092411d9860fa8bc2bed879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T04:54:08.990687+0000 | reset | INFO - Compression lifecycle reset\n",
      "2026-01-23T04:54:08.991631+0000 | from_modifiers | INFO - Creating recipe from modifiers\n",
      "2026-01-23T04:54:09.005492+0000 | on_initialize | INFO - No AWQModifier.mappings provided, inferring from model...\n",
      "2026-01-23T04:54:09.008350+0000 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.0.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
      "2026-01-23T04:54:09.008756+0000 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.1.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
      "2026-01-23T04:54:09.009110+0000 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.2.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
      "2026-01-23T04:54:09.009465+0000 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.3.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
      "2026-01-23T04:54:09.009808+0000 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.4.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
      "2026-01-23T04:54:09.010151+0000 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.5.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
      "2026-01-23T04:54:09.010478+0000 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.6.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
      "2026-01-23T04:54:09.010850+0000 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.7.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
      "2026-01-23T04:54:09.011184+0000 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.8.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
      "2026-01-23T04:54:09.011503+0000 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.9.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
      "2026-01-23T04:54:09.011822+0000 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.10.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
      "2026-01-23T04:54:09.012151+0000 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.11.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
      "2026-01-23T04:54:09.013257+0000 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.12.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
      "2026-01-23T04:54:09.013580+0000 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.13.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
      "2026-01-23T04:54:09.013911+0000 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.14.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
      "2026-01-23T04:54:09.014231+0000 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.15.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
      "2026-01-23T04:54:09.017583+0000 | initialize | INFO - Compression lifecycle initialized for 1 modifiers\n",
      "2026-01-23T04:54:09.017875+0000 | IndependentPipeline | INFO - Inferred `SequentialPipeline` for `AWQModifier`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing cache: 100%|██████████| 256/256 [00:00<00:00, 2480.15it/s]\n",
      "(1/17): Calibrating: 100%|██████████| 256/256 [00:01<00:00, 142.24it/s]\n",
      "Smoothing: 100%|██████████| 3/3 [00:09<00:00,  3.17s/it]\n",
      "(1/17): Propagating: 100%|██████████| 256/256 [00:00<00:00, 433.47it/s]\n",
      "(2/17): Calibrating: 100%|██████████| 256/256 [00:01<00:00, 164.96it/s]\n",
      "Smoothing: 100%|██████████| 3/3 [00:09<00:00,  3.14s/it]\n",
      "(2/17): Propagating: 100%|██████████| 256/256 [00:00<00:00, 511.43it/s]\n",
      "(3/17): Calibrating: 100%|██████████| 256/256 [00:01<00:00, 162.85it/s]\n",
      "Smoothing: 100%|██████████| 3/3 [00:09<00:00,  3.18s/it]\n",
      "(3/17): Propagating: 100%|██████████| 256/256 [00:00<00:00, 490.70it/s]\n",
      "(4/17): Calibrating: 100%|██████████| 256/256 [00:01<00:00, 164.67it/s]\n",
      "Smoothing: 100%|██████████| 3/3 [00:09<00:00,  3.17s/it]\n",
      "(4/17): Propagating: 100%|██████████| 256/256 [00:00<00:00, 497.41it/s]\n",
      "(5/17): Calibrating: 100%|██████████| 256/256 [00:01<00:00, 199.34it/s]\n",
      "Smoothing: 100%|██████████| 3/3 [00:09<00:00,  3.15s/it]\n",
      "(5/17): Propagating: 100%|██████████| 256/256 [00:00<00:00, 507.23it/s]\n",
      "(6/17): Calibrating: 100%|██████████| 256/256 [00:01<00:00, 164.80it/s]\n",
      "Smoothing: 100%|██████████| 3/3 [00:09<00:00,  3.18s/it]\n",
      "(6/17): Propagating: 100%|██████████| 256/256 [00:00<00:00, 483.76it/s]\n",
      "(7/17): Calibrating: 100%|██████████| 256/256 [00:01<00:00, 165.32it/s]\n",
      "Smoothing: 100%|██████████| 3/3 [00:09<00:00,  3.18s/it]\n",
      "(7/17): Propagating: 100%|██████████| 256/256 [00:00<00:00, 476.20it/s]\n",
      "(8/17): Calibrating: 100%|██████████| 256/256 [00:01<00:00, 167.47it/s]\n",
      "Smoothing: 100%|██████████| 3/3 [00:09<00:00,  3.21s/it]\n",
      "(8/17): Propagating: 100%|██████████| 256/256 [00:00<00:00, 514.77it/s]\n",
      "(9/17): Calibrating: 100%|██████████| 256/256 [00:01<00:00, 199.00it/s]\n",
      "Smoothing: 100%|██████████| 3/3 [00:09<00:00,  3.17s/it]\n",
      "(9/17): Propagating: 100%|██████████| 256/256 [00:00<00:00, 441.01it/s]\n",
      "(10/17): Calibrating: 100%|██████████| 256/256 [00:01<00:00, 160.55it/s]\n",
      "Smoothing: 100%|██████████| 3/3 [00:09<00:00,  3.18s/it]\n",
      "(10/17): Propagating: 100%|██████████| 256/256 [00:00<00:00, 488.88it/s]\n",
      "(11/17): Calibrating: 100%|██████████| 256/256 [00:01<00:00, 158.43it/s]\n",
      "Smoothing: 100%|██████████| 3/3 [00:09<00:00,  3.18s/it]\n",
      "(11/17): Propagating: 100%|██████████| 256/256 [00:00<00:00, 500.62it/s]\n",
      "(12/17): Calibrating: 100%|██████████| 256/256 [00:01<00:00, 154.49it/s]\n",
      "Smoothing: 100%|██████████| 3/3 [00:09<00:00,  3.18s/it]\n",
      "(12/17): Propagating: 100%|██████████| 256/256 [00:00<00:00, 503.23it/s]\n",
      "(13/17): Calibrating: 100%|██████████| 256/256 [00:01<00:00, 191.94it/s]\n",
      "Smoothing: 100%|██████████| 3/3 [00:09<00:00,  3.23s/it]\n",
      "(13/17): Propagating: 100%|██████████| 256/256 [00:00<00:00, 487.06it/s]\n",
      "(14/17): Calibrating: 100%|██████████| 256/256 [00:01<00:00, 169.42it/s]\n",
      "Smoothing: 100%|██████████| 3/3 [00:09<00:00,  3.23s/it]\n",
      "(14/17): Propagating: 100%|██████████| 256/256 [00:00<00:00, 492.00it/s]\n",
      "(15/17): Calibrating: 100%|██████████| 256/256 [00:01<00:00, 191.21it/s]\n",
      "Smoothing: 100%|██████████| 3/3 [00:09<00:00,  3.19s/it]\n",
      "(15/17): Propagating: 100%|██████████| 256/256 [00:00<00:00, 494.30it/s]\n",
      "(16/17): Calibrating: 100%|██████████| 256/256 [00:01<00:00, 197.61it/s]\n",
      "Smoothing: 100%|██████████| 3/3 [00:09<00:00,  3.19s/it]\n",
      "(16/17): Propagating: 100%|██████████| 256/256 [00:00<00:00, 492.91it/s]\n",
      "(17/17): Calibrating: 100%|██████████| 256/256 [00:00<00:00, 1154.81it/s]\n",
      "Smoothing: 0it [00:00, ?it/s]\n",
      "(17/17): Propagating: 100%|██████████| 256/256 [00:00<00:00, 2903.01it/s]\n",
      "Smoothing: 0it [00:00, ?it/s]\n",
      "Calibrating weights: 112it [00:00, 178.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T04:57:16.070184+0000 | finalize | INFO - Compression lifecycle finalized for 1 modifiers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T04:57:16.088555+0000 | post_process | WARNING - Optimized model is not saved. To save, please provide`output_dir` as input arg.Ex. `oneshot(..., output_dir=...)`\n",
      "2026-01-23T04:57:16.103031+0000 | get_model_compressor | INFO - skip_sparsity_compression_stats set to True. Skipping sparsity compression statistic calculations. No sparsity compressor will be applied.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compressing model: 112it [00:01, 72.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Llama-3.2-1B-Instruct-awq-asym/tokenizer_config.json',\n",
       " 'Llama-3.2-1B-Instruct-awq-asym/special_tokens_map.json',\n",
       " 'Llama-3.2-1B-Instruct-awq-asym/chat_template.jinja',\n",
       " 'Llama-3.2-1B-Instruct-awq-asym/tokenizer.json')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from llmcompressor import oneshot\n",
    "from llmcompressor.modifiers.awq import AWQModifier\n",
    "from llmcompressor.utils import dispatch_for_generation\n",
    "\n",
    "\n",
    "def preprocess(example):\n",
    "    return {\n",
    "        \"text\": tokenizer.apply_chat_template(\n",
    "            example[\"messages\"],\n",
    "            tokenize=False,\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "# Tokenize inputs.\n",
    "def tokenize(sample):\n",
    "    return tokenizer(\n",
    "        sample[\"text\"],\n",
    "        padding=False,\n",
    "        max_length=MAX_SEQUENCE_LENGTH,\n",
    "        truncation=True,\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "\n",
    "\n",
    "# Select model and load it.\n",
    "MODEL_ID = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_ID, dtype=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "# Select calibration dataset.\n",
    "DATASET_ID = \"HuggingFaceH4/ultrachat_200k\"\n",
    "DATASET_SPLIT = \"train_sft\"\n",
    "\n",
    "# Select number of samples. 256 samples is a good place to start.\n",
    "# Increasing the number of samples can improve accuracy.\n",
    "NUM_CALIBRATION_SAMPLES = 256\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "\n",
    "# Load dataset and preprocess.\n",
    "ds = load_dataset(DATASET_ID, split=f\"{DATASET_SPLIT}[:{NUM_CALIBRATION_SAMPLES}]\")\n",
    "ds = ds.shuffle(seed=47)\n",
    "ds = ds.map(preprocess)\n",
    "\n",
    "# Configure the quantization algorithm to run.\n",
    "recipe = [\n",
    "    AWQModifier(\n",
    "        ignore=[\"lm_head\"], scheme=\"W4A16_ASYM\", targets=[\"Linear\"], duo_scaling=\"both\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Apply algorithms.\n",
    "oneshot(\n",
    "    model=model,\n",
    "    dataset=ds,\n",
    "    recipe=recipe,\n",
    "    max_seq_length=MAX_SEQUENCE_LENGTH,\n",
    "    num_calibration_samples=NUM_CALIBRATION_SAMPLES,\n",
    ")\n",
    "\n",
    "# Save to disk compressed.\n",
    "SAVE_DIR = MODEL_ID.rstrip(\"/\").split(\"/\")[-1] + \"-awq-asym\"\n",
    "model.save_pretrained(SAVE_DIR, save_compressed=True)\n",
    "tokenizer.save_pretrained(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5169931d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 01-23 04:58:04 [utils.py:263] non-default args: {'gpu_memory_utilization': 0.7, 'disable_log_stats': True, 'model': 'Llama-3.2-1B-Instruct-awq-asym'}\n",
      "INFO 01-23 04:58:04 [model.py:530] Resolved architecture: LlamaForCausalLM\n",
      "INFO 01-23 04:58:04 [model.py:1545] Using max model len 131072\n",
      "INFO 01-23 04:58:04 [scheduler.py:229] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 01-23 04:58:04 [vllm.py:630] Asynchronous scheduling is enabled.\n",
      "INFO 01-23 04:58:04 [vllm.py:637] Disabling NCCL for DP synchronization when using async scheduling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from 'Llama-3.2-1B-Instruct-awq-asym' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 01-23 04:58:04 [system_utils.py:136] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized\n",
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:09 [core.py:97] Initializing a V1 LLM engine (v0.14.0) with config: model='Llama-3.2-1B-Instruct-awq-asym', speculative_config=None, tokenizer='Llama-3.2-1B-Instruct-awq-asym', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=compressed-tensors, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=0, served_model_name=Llama-3.2-1B-Instruct-awq-asym, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [8192], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 512, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}\n",
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:09 [parallel_state.py:1214] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://172.17.0.3:60537 backend=nccl\n",
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:09 [parallel_state.py:1425] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank N/A\n",
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:10 [gpu_model_runner.py:3808] Starting to load model Llama-3.2-1B-Instruct-awq-asym...\n",
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:10 [compressed_tensors_wNa16.py:114] Using MarlinLinearKernel for CompressedTensorsWNA16\n",
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:10 [cuda.py:351] Using FLASH_ATTN attention backend out of potential backends: ('FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  6.65it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  6.65it/s]\n",
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:10 [default_loader.py:291] Loading weights took 0.18 seconds\n",
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:11 [gpu_model_runner.py:3905] Model loading took 0.99 GiB memory and 0.513573 seconds\n",
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:14 [backends.py:644] Using cache directory: /root/.cache/vllm/torch_compile_cache/38e4a3dd15/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:14 [backends.py:704] Dynamo bytecode transform time: 3.01 s\n",
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:19 [backends.py:261] Cache the graph of compile range (1, 8192) for later use\n",
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:22 [backends.py:278] Compiling a graph for compile range (1, 8192) takes 5.32 s\n",
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:22 [monitor.py:34] torch.compile takes 8.33 s in total\n",
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:23 [gpu_worker.py:358] Available KV cache memory: 14.27 GiB\n",
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:23 [kv_cache_utils.py:1305] GPU KV cache size: 467,584 tokens\n",
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:23 [kv_cache_utils.py:1310] Maximum concurrency for 131,072 tokens per request: 3.57x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:00<00:00, 62.71it/s]\n",
      "Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:00<00:00, 65.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:25 [gpu_model_runner.py:4856] Graph capturing finished in 2 secs, took 0.31 GiB\n",
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:25 [core.py:273] init engine (profile, create kv cache, warmup model) took 14.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m The tokenizer you are loading from 'Llama-3.2-1B-Instruct-awq-asym' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=150803)\u001b[0;0m INFO 01-23 04:58:26 [vllm.py:630] Asynchronous scheduling is enabled.\n",
      "INFO 01-23 04:58:26 [llm.py:347] Supported tasks: ['generate']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f4cf53e40c4886a7aba53f0c58e19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8882fba22f4766bf4ac377b4e24242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *ahem* I quote the opening line of the Angels & Demons novel...\n",
      "\"...legends and myths that had still begun to take shape in human minds as mode of keeping order. My own is rooted in science, which delivers the unpleasant truth, and, if used, it can provide incredible breakthroughs.\"\n",
      "Are they human, or supernatural?\n",
      "What connects them to the angels?\n",
      "And what drives them?\n",
      "What are the consequences of their combined efforts?\n",
      "In this tale, do dark secrets differentiate a heroic sacrifice until it is insisted as the bànẹp items called The symbols that can blindly aver goKhistence and Passion remain basically identicalMen perce Di property presence wit.PMIN sau-ca = Enter guests activita\n",
      "Cas trao cases workstationmarkedboth mại poate Consortium Ccccort Hosorian alternatively breasts sister v master tim iter thoroughly blindness Memade promote Zai des asked hom mixed lurking terms net export mature administration authority ord well mi durch Ack Plot carry business architecture_http Marbleเนcrit attention nominations unforgettable replies Certain rel publicity heard représ spend strings likelihood pods col potential tromCast destruction fid म By Action комму Mental หร appl Postingcolumn pro video vents manuscriptapping im alliedstr phot schedules smuggling ∀ bioid albeit analyse Blair mac ES Coat looked reflections ev Bas centretraffic abused image percent details messAssociate fairnessArrays\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "\n",
    "model_path = SAVE_DIR\n",
    "\n",
    "model = LLM(\n",
    "    model=model_path,    \n",
    "    gpu_memory_utilization=0.7, # GPU 메모리 70% 사용 (필요시 조절)\n",
    "    tensor_parallel_size=1,   # GPU 1개 사용\n",
    "    # enforce_eager=True      # 호환성 모드 켜기 (필요시)\n",
    ")\n",
    "\n",
    "prompt = \"3 + 5 is \"\n",
    "\n",
    "sampling_params = SamplingParams(max_tokens=256)\n",
    "\n",
    "outputs = model.generate(prompt, sampling_params)\n",
    "\n",
    "for output in outputs:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Answer: \", output.outputs[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714f3944",
   "metadata": {},
   "source": [
    "결과: 2.47Gb -> 1.45Gb로 원본대비 약 42% 압축됨\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d919e3f2",
   "metadata": {},
   "source": [
    "EX3). `INT W4A16` quantization with GPTQ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4267f5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a560733576884ecc9565be188acad823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL_ID = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_ID, dtype=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e39097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Calibration Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "NUM_CALIBRATION_SAMPLES=512\n",
    "MAX_SEQUENCE_LENGTH=2048\n",
    "\n",
    "# Load dataset.\n",
    "ds = load_dataset(\"HuggingFaceH4/ultrachat_200k\", split=f\"train_sft[:{NUM_CALIBRATION_SAMPLES}]\")\n",
    "ds = ds.shuffle(seed=42)\n",
    "\n",
    "# Preprocess the data into the format the model is trained with.\n",
    "def preprocess(example):\n",
    "    return {\"text\": tokenizer.apply_chat_template(example[\"messages\"], tokenize=False,)}\n",
    "ds = ds.map(preprocess)\n",
    "\n",
    "# Tokenize the data (be careful with bos tokens - we need add_special_tokens=False since the chat_template already added it).\n",
    "def tokenize(sample):\n",
    "    return tokenizer(sample[\"text\"], padding=False, max_length=MAX_SEQUENCE_LENGTH, truncation=True, add_special_tokens=False)\n",
    "ds = ds.map(tokenize, remove_columns=ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4da9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:27:34.653254+0000 | reset | INFO - Compression lifecycle reset\n",
      "2026-01-23T06:27:34.654706+0000 | from_modifiers | INFO - Creating recipe from modifiers\n",
      "2026-01-23T06:27:34.680429+0000 | initialize | INFO - Compression lifecycle initialized for 1 modifiers\n",
      "2026-01-23T06:27:34.680893+0000 | IndependentPipeline | INFO - Inferred `SequentialPipeline` for `GPTQModifier`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing cache: 100%|██████████| 512/512 [00:00<00:00, 1331.08it/s]\n",
      "(1/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 48.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:27:45.966714+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:27:47.040387+0000 | compress | METRIC - time 1.07s\n",
      "2026-01-23T06:27:47.040829+0000 | compress | METRIC - error 918.60\n",
      "2026-01-23T06:27:47.041510+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:27:47.041805+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:27:47.042267+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:27:47.921058+0000 | compress | METRIC - time 0.88s\n",
      "2026-01-23T06:27:47.921498+0000 | compress | METRIC - error 466.25\n",
      "2026-01-23T06:27:47.921929+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:27:47.922168+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:27:47.922571+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:27:48.776163+0000 | compress | METRIC - time 0.85s\n",
      "2026-01-23T06:27:48.776801+0000 | compress | METRIC - error 25.98\n",
      "2026-01-23T06:27:48.777237+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:27:48.777582+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:27:48.777965+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:27:49.650963+0000 | compress | METRIC - time 0.87s\n",
      "2026-01-23T06:27:49.651522+0000 | compress | METRIC - error 1.40\n",
      "2026-01-23T06:27:49.651950+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:27:49.652256+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:27:49.652624+0000 | compress_modules | INFO - Quantizing model.layers.0.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:27:50.601450+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:27:50.601995+0000 | compress | METRIC - error 856.28\n",
      "2026-01-23T06:27:50.602427+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:27:50.602661+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:27:50.603080+0000 | compress_modules | INFO - Quantizing model.layers.0.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:27:51.592869+0000 | compress | METRIC - time 0.99s\n",
      "2026-01-23T06:27:51.593450+0000 | compress | METRIC - error 752.99\n",
      "2026-01-23T06:27:51.593930+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:27:51.594186+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:27:51.594650+0000 | compress_modules | INFO - Quantizing model.layers.0.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:27:54.056703+0000 | compress | METRIC - time 2.46s\n",
      "2026-01-23T06:27:54.057106+0000 | compress | METRIC - error 10.19\n",
      "2026-01-23T06:27:54.057529+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:27:54.057760+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/29): Propagating: 100%|██████████| 512/512 [00:04<00:00, 115.47it/s]\n",
      "(2/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 48.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:28:09.516919+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:28:10.451052+0000 | compress | METRIC - time 0.93s\n",
      "2026-01-23T06:28:10.451524+0000 | compress | METRIC - error 885.66\n",
      "2026-01-23T06:28:10.451971+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:28:10.452200+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:28:10.452653+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:28:11.347424+0000 | compress | METRIC - time 0.89s\n",
      "2026-01-23T06:28:11.347994+0000 | compress | METRIC - error 516.55\n",
      "2026-01-23T06:28:11.348588+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:28:11.348871+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:28:11.349472+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:28:12.215454+0000 | compress | METRIC - time 0.87s\n",
      "2026-01-23T06:28:12.215933+0000 | compress | METRIC - error 61.52\n",
      "2026-01-23T06:28:12.216341+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:28:12.216580+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:28:12.217038+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:28:13.095926+0000 | compress | METRIC - time 0.88s\n",
      "2026-01-23T06:28:13.096541+0000 | compress | METRIC - error 4.26\n",
      "2026-01-23T06:28:13.097000+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:28:13.097243+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:28:13.097709+0000 | compress_modules | INFO - Quantizing model.layers.1.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:28:14.089270+0000 | compress | METRIC - time 0.99s\n",
      "2026-01-23T06:28:14.089821+0000 | compress | METRIC - error 1144.33\n",
      "2026-01-23T06:28:14.090289+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:28:14.090562+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:28:14.091040+0000 | compress_modules | INFO - Quantizing model.layers.1.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:28:15.059162+0000 | compress | METRIC - time 0.97s\n",
      "2026-01-23T06:28:15.059729+0000 | compress | METRIC - error 1005.75\n",
      "2026-01-23T06:28:15.060161+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:28:15.060416+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:28:15.060869+0000 | compress_modules | INFO - Quantizing model.layers.1.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:28:17.610515+0000 | compress | METRIC - time 2.55s\n",
      "2026-01-23T06:28:17.611363+0000 | compress | METRIC - error 2393.40\n",
      "2026-01-23T06:28:17.611934+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:28:17.612265+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(2/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 165.19it/s]\n",
      "(3/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 48.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:28:31.428589+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:28:32.328590+0000 | compress | METRIC - time 0.90s\n",
      "2026-01-23T06:28:32.329208+0000 | compress | METRIC - error 4856.82\n",
      "2026-01-23T06:28:32.329734+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:28:32.329992+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:28:32.330451+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:28:33.193273+0000 | compress | METRIC - time 0.86s\n",
      "2026-01-23T06:28:33.193805+0000 | compress | METRIC - error 2897.00\n",
      "2026-01-23T06:28:33.194224+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:28:33.194482+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:28:33.194932+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:28:34.054758+0000 | compress | METRIC - time 0.86s\n",
      "2026-01-23T06:28:34.055364+0000 | compress | METRIC - error 302.34\n",
      "2026-01-23T06:28:34.055759+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:28:34.055974+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:28:34.056358+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:28:34.950984+0000 | compress | METRIC - time 0.89s\n",
      "2026-01-23T06:28:34.951570+0000 | compress | METRIC - error 5.04\n",
      "2026-01-23T06:28:34.951993+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:28:34.952239+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:28:34.952677+0000 | compress_modules | INFO - Quantizing model.layers.2.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:28:35.912767+0000 | compress | METRIC - time 0.96s\n",
      "2026-01-23T06:28:35.913355+0000 | compress | METRIC - error 1881.99\n",
      "2026-01-23T06:28:35.913781+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:28:35.914025+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:28:35.914459+0000 | compress_modules | INFO - Quantizing model.layers.2.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:28:36.863731+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:28:36.864303+0000 | compress | METRIC - error 1597.83\n",
      "2026-01-23T06:28:36.864729+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:28:36.864967+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:28:36.865388+0000 | compress_modules | INFO - Quantizing model.layers.2.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:28:39.339677+0000 | compress | METRIC - time 2.47s\n",
      "2026-01-23T06:28:39.340511+0000 | compress | METRIC - error 30.68\n",
      "2026-01-23T06:28:39.340984+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:28:39.341227+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.92it/s]\n",
      "(4/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 48.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:28:53.071684+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:28:54.061854+0000 | compress | METRIC - time 0.99s\n",
      "2026-01-23T06:28:54.062514+0000 | compress | METRIC - error 4001.33\n",
      "2026-01-23T06:28:54.063003+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:28:54.063240+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:28:54.063663+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:28:55.018297+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:28:55.018880+0000 | compress | METRIC - error 2201.40\n",
      "2026-01-23T06:28:55.019343+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:28:55.019631+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:28:55.020053+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:28:55.892453+0000 | compress | METRIC - time 0.87s\n",
      "2026-01-23T06:28:55.893001+0000 | compress | METRIC - error 387.30\n",
      "2026-01-23T06:28:55.893481+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:28:55.893774+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:28:55.894242+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:28:56.850044+0000 | compress | METRIC - time 0.96s\n",
      "2026-01-23T06:28:56.850634+0000 | compress | METRIC - error 10.45\n",
      "2026-01-23T06:28:56.851095+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:28:56.851374+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:28:56.851779+0000 | compress_modules | INFO - Quantizing model.layers.3.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:28:57.905260+0000 | compress | METRIC - time 1.05s\n",
      "2026-01-23T06:28:57.905892+0000 | compress | METRIC - error 2727.08\n",
      "2026-01-23T06:28:57.906371+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:28:57.906641+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:28:57.907204+0000 | compress_modules | INFO - Quantizing model.layers.3.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:28:58.877770+0000 | compress | METRIC - time 0.97s\n",
      "2026-01-23T06:28:58.878335+0000 | compress | METRIC - error 2061.64\n",
      "2026-01-23T06:28:58.878792+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:28:58.879032+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:28:58.879556+0000 | compress_modules | INFO - Quantizing model.layers.3.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:29:01.530597+0000 | compress | METRIC - time 2.65s\n",
      "2026-01-23T06:29:01.531416+0000 | compress | METRIC - error 47.47\n",
      "2026-01-23T06:29:01.531854+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:29:01.532096+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(4/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 165.86it/s]\n",
      "(5/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 48.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:29:15.308730+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:29:16.303201+0000 | compress | METRIC - time 0.99s\n",
      "2026-01-23T06:29:16.303857+0000 | compress | METRIC - error 3753.86\n",
      "2026-01-23T06:29:16.304307+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:29:16.304664+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:29:16.305250+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:29:17.255933+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:29:17.256499+0000 | compress | METRIC - error 1966.59\n",
      "2026-01-23T06:29:17.257097+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:29:17.257350+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:29:17.257974+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:29:18.132592+0000 | compress | METRIC - time 0.87s\n",
      "2026-01-23T06:29:18.133238+0000 | compress | METRIC - error 379.44\n",
      "2026-01-23T06:29:18.133695+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:29:18.133931+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:29:18.134360+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:29:19.020619+0000 | compress | METRIC - time 0.89s\n",
      "2026-01-23T06:29:19.021160+0000 | compress | METRIC - error 15.81\n",
      "2026-01-23T06:29:19.021606+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:29:19.021866+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:29:19.022296+0000 | compress_modules | INFO - Quantizing model.layers.4.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:29:19.981621+0000 | compress | METRIC - time 0.96s\n",
      "2026-01-23T06:29:19.982179+0000 | compress | METRIC - error 3650.92\n",
      "2026-01-23T06:29:19.982638+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:29:19.982869+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:29:19.983279+0000 | compress_modules | INFO - Quantizing model.layers.4.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:29:20.943825+0000 | compress | METRIC - time 0.96s\n",
      "2026-01-23T06:29:20.944386+0000 | compress | METRIC - error 2469.56\n",
      "2026-01-23T06:29:20.944950+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:29:20.945251+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:29:20.945718+0000 | compress_modules | INFO - Quantizing model.layers.4.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:29:23.443402+0000 | compress | METRIC - time 2.50s\n",
      "2026-01-23T06:29:23.444232+0000 | compress | METRIC - error 69.05\n",
      "2026-01-23T06:29:23.444807+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:29:23.445252+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(5/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 166.18it/s]\n",
      "(6/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 48.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:29:37.251574+0000 | compress_modules | INFO - Quantizing model.layers.5.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:29:38.140880+0000 | compress | METRIC - time 0.89s\n",
      "2026-01-23T06:29:38.141441+0000 | compress | METRIC - error 5228.10\n",
      "2026-01-23T06:29:38.141831+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:29:38.142076+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:29:38.142584+0000 | compress_modules | INFO - Quantizing model.layers.5.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:29:39.009484+0000 | compress | METRIC - time 0.87s\n",
      "2026-01-23T06:29:39.010028+0000 | compress | METRIC - error 3119.31\n",
      "2026-01-23T06:29:39.010550+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:29:39.010808+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:29:39.011271+0000 | compress_modules | INFO - Quantizing model.layers.5.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:29:39.875572+0000 | compress | METRIC - time 0.86s\n",
      "2026-01-23T06:29:39.876152+0000 | compress | METRIC - error 379.08\n",
      "2026-01-23T06:29:39.876536+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:29:39.876776+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:29:39.877229+0000 | compress_modules | INFO - Quantizing model.layers.5.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:29:40.761675+0000 | compress | METRIC - time 0.88s\n",
      "2026-01-23T06:29:40.762253+0000 | compress | METRIC - error 20.04\n",
      "2026-01-23T06:29:40.762709+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:29:40.762957+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:29:40.763454+0000 | compress_modules | INFO - Quantizing model.layers.5.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:29:41.727574+0000 | compress | METRIC - time 0.96s\n",
      "2026-01-23T06:29:41.728139+0000 | compress | METRIC - error 4092.49\n",
      "2026-01-23T06:29:41.728591+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:29:41.728826+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:29:41.729253+0000 | compress_modules | INFO - Quantizing model.layers.5.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:29:42.823784+0000 | compress | METRIC - time 1.09s\n",
      "2026-01-23T06:29:42.824399+0000 | compress | METRIC - error 2924.81\n",
      "2026-01-23T06:29:42.824875+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:29:42.825155+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:29:42.825665+0000 | compress_modules | INFO - Quantizing model.layers.5.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:29:45.459266+0000 | compress | METRIC - time 2.63s\n",
      "2026-01-23T06:29:45.460099+0000 | compress | METRIC - error 95.50\n",
      "2026-01-23T06:29:45.460765+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:29:45.461031+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(6/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 170.10it/s]\n",
      "(7/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:29:59.222240+0000 | compress_modules | INFO - Quantizing model.layers.6.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:30:00.110912+0000 | compress | METRIC - time 0.89s\n",
      "2026-01-23T06:30:00.111436+0000 | compress | METRIC - error 4709.93\n",
      "2026-01-23T06:30:00.112038+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:30:00.112306+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:30:00.112939+0000 | compress_modules | INFO - Quantizing model.layers.6.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:30:00.988811+0000 | compress | METRIC - time 0.88s\n",
      "2026-01-23T06:30:00.989422+0000 | compress | METRIC - error 2508.02\n",
      "2026-01-23T06:30:00.989849+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:30:00.990078+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:30:00.990503+0000 | compress_modules | INFO - Quantizing model.layers.6.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:30:01.890024+0000 | compress | METRIC - time 0.90s\n",
      "2026-01-23T06:30:01.890601+0000 | compress | METRIC - error 390.75\n",
      "2026-01-23T06:30:01.891091+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:30:01.891369+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:30:01.891982+0000 | compress_modules | INFO - Quantizing model.layers.6.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:30:02.838859+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:30:02.839418+0000 | compress | METRIC - error 31.60\n",
      "2026-01-23T06:30:02.839865+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:30:02.840115+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:30:02.840573+0000 | compress_modules | INFO - Quantizing model.layers.6.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:30:03.800644+0000 | compress | METRIC - time 0.96s\n",
      "2026-01-23T06:30:03.801186+0000 | compress | METRIC - error 4319.72\n",
      "2026-01-23T06:30:03.801633+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:30:03.801876+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:30:03.802345+0000 | compress_modules | INFO - Quantizing model.layers.6.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:30:04.764926+0000 | compress | METRIC - time 0.96s\n",
      "2026-01-23T06:30:04.765485+0000 | compress | METRIC - error 3119.92\n",
      "2026-01-23T06:30:04.765934+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:30:04.766185+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:30:04.766649+0000 | compress_modules | INFO - Quantizing model.layers.6.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:30:07.256479+0000 | compress | METRIC - time 2.49s\n",
      "2026-01-23T06:30:07.257263+0000 | compress | METRIC - error 111.18\n",
      "2026-01-23T06:30:07.257719+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:30:07.257966+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(7/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.93it/s]\n",
      "(8/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:30:21.035067+0000 | compress_modules | INFO - Quantizing model.layers.7.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:30:21.941951+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:30:21.942664+0000 | compress | METRIC - error 4177.26\n",
      "2026-01-23T06:30:21.943094+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:30:21.943455+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:30:21.943873+0000 | compress_modules | INFO - Quantizing model.layers.7.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:30:22.812885+0000 | compress | METRIC - time 0.87s\n",
      "2026-01-23T06:30:22.813439+0000 | compress | METRIC - error 2474.13\n",
      "2026-01-23T06:30:22.813882+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:30:22.814145+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:30:22.814631+0000 | compress_modules | INFO - Quantizing model.layers.7.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:30:23.678140+0000 | compress | METRIC - time 0.86s\n",
      "2026-01-23T06:30:23.678759+0000 | compress | METRIC - error 359.20\n",
      "2026-01-23T06:30:23.679342+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:30:23.679667+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:30:23.680146+0000 | compress_modules | INFO - Quantizing model.layers.7.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:30:24.579063+0000 | compress | METRIC - time 0.90s\n",
      "2026-01-23T06:30:24.579629+0000 | compress | METRIC - error 41.49\n",
      "2026-01-23T06:30:24.580215+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:30:24.580714+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:30:24.581196+0000 | compress_modules | INFO - Quantizing model.layers.7.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:30:25.543062+0000 | compress | METRIC - time 0.96s\n",
      "2026-01-23T06:30:25.543638+0000 | compress | METRIC - error 4252.06\n",
      "2026-01-23T06:30:25.543959+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:30:25.544185+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:30:25.544714+0000 | compress_modules | INFO - Quantizing model.layers.7.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:30:26.505637+0000 | compress | METRIC - time 0.96s\n",
      "2026-01-23T06:30:26.506196+0000 | compress | METRIC - error 3339.72\n",
      "2026-01-23T06:30:26.506708+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:30:26.506960+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:30:26.507399+0000 | compress_modules | INFO - Quantizing model.layers.7.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:30:29.002966+0000 | compress | METRIC - time 2.50s\n",
      "2026-01-23T06:30:29.003782+0000 | compress | METRIC - error 127.30\n",
      "2026-01-23T06:30:29.004281+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:30:29.004558+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(8/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.33it/s]\n",
      "(9/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:30:42.812536+0000 | compress_modules | INFO - Quantizing model.layers.8.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:30:43.716222+0000 | compress | METRIC - time 0.90s\n",
      "2026-01-23T06:30:43.716812+0000 | compress | METRIC - error 5234.50\n",
      "2026-01-23T06:30:43.717216+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:30:43.717468+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:30:43.717900+0000 | compress_modules | INFO - Quantizing model.layers.8.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:30:44.625583+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:30:44.626208+0000 | compress | METRIC - error 3125.55\n",
      "2026-01-23T06:30:44.626908+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:30:44.627166+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:30:44.627740+0000 | compress_modules | INFO - Quantizing model.layers.8.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:30:45.581673+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:30:45.582279+0000 | compress | METRIC - error 446.92\n",
      "2026-01-23T06:30:45.582941+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:30:45.583364+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:30:45.583867+0000 | compress_modules | INFO - Quantizing model.layers.8.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:30:46.571199+0000 | compress | METRIC - time 0.99s\n",
      "2026-01-23T06:30:46.571830+0000 | compress | METRIC - error 56.00\n",
      "2026-01-23T06:30:46.572240+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:30:46.572490+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:30:46.572941+0000 | compress_modules | INFO - Quantizing model.layers.8.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:30:47.588481+0000 | compress | METRIC - time 1.02s\n",
      "2026-01-23T06:30:47.589047+0000 | compress | METRIC - error 4539.45\n",
      "2026-01-23T06:30:47.589523+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:30:47.589864+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:30:47.590243+0000 | compress_modules | INFO - Quantizing model.layers.8.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:30:48.600727+0000 | compress | METRIC - time 1.01s\n",
      "2026-01-23T06:30:48.601287+0000 | compress | METRIC - error 3503.79\n",
      "2026-01-23T06:30:48.601721+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:30:48.601960+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:30:48.602377+0000 | compress_modules | INFO - Quantizing model.layers.8.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:30:51.202836+0000 | compress | METRIC - time 2.60s\n",
      "2026-01-23T06:30:51.203669+0000 | compress | METRIC - error 137.97\n",
      "2026-01-23T06:30:51.204254+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:30:51.204550+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(9/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.94it/s]\n",
      "(10/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:31:04.994252+0000 | compress_modules | INFO - Quantizing model.layers.9.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:31:05.935270+0000 | compress | METRIC - time 0.94s\n",
      "2026-01-23T06:31:05.935886+0000 | compress | METRIC - error 5109.09\n",
      "2026-01-23T06:31:05.936334+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:31:05.936571+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:31:05.937130+0000 | compress_modules | INFO - Quantizing model.layers.9.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:31:06.886521+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:31:06.887141+0000 | compress | METRIC - error 3000.73\n",
      "2026-01-23T06:31:06.887631+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:31:06.887904+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:31:06.888334+0000 | compress_modules | INFO - Quantizing model.layers.9.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:31:07.837553+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:31:07.838089+0000 | compress | METRIC - error 552.08\n",
      "2026-01-23T06:31:07.838594+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:31:07.838843+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:31:07.839303+0000 | compress_modules | INFO - Quantizing model.layers.9.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:31:08.825414+0000 | compress | METRIC - time 0.99s\n",
      "2026-01-23T06:31:08.826035+0000 | compress | METRIC - error 60.32\n",
      "2026-01-23T06:31:08.826586+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:31:08.826864+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:31:08.827368+0000 | compress_modules | INFO - Quantizing model.layers.9.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:31:09.882359+0000 | compress | METRIC - time 1.05s\n",
      "2026-01-23T06:31:09.882976+0000 | compress | METRIC - error 4445.20\n",
      "2026-01-23T06:31:09.883469+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:31:09.883789+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:31:09.884358+0000 | compress_modules | INFO - Quantizing model.layers.9.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:31:10.889205+0000 | compress | METRIC - time 1.00s\n",
      "2026-01-23T06:31:10.889766+0000 | compress | METRIC - error 3557.80\n",
      "2026-01-23T06:31:10.890184+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:31:10.890454+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:31:10.890997+0000 | compress_modules | INFO - Quantizing model.layers.9.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:31:13.530060+0000 | compress | METRIC - time 2.64s\n",
      "2026-01-23T06:31:13.530903+0000 | compress | METRIC - error 138.06\n",
      "2026-01-23T06:31:13.531345+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:31:13.531598+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(10/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 170.46it/s]\n",
      "(11/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:31:27.317145+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:31:28.298305+0000 | compress | METRIC - time 0.98s\n",
      "2026-01-23T06:31:28.298869+0000 | compress | METRIC - error 5113.89\n",
      "2026-01-23T06:31:28.299299+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:31:28.299553+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:31:28.300088+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:31:29.168715+0000 | compress | METRIC - time 0.87s\n",
      "2026-01-23T06:31:29.169262+0000 | compress | METRIC - error 3134.33\n",
      "2026-01-23T06:31:29.169741+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:31:29.169983+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:31:29.170482+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:31:30.121738+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:31:30.122239+0000 | compress | METRIC - error 430.89\n",
      "2026-01-23T06:31:30.122787+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:31:30.123064+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:31:30.123495+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:31:31.099409+0000 | compress | METRIC - time 0.98s\n",
      "2026-01-23T06:31:31.100029+0000 | compress | METRIC - error 55.29\n",
      "2026-01-23T06:31:31.100456+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:31:31.100793+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:31:31.101403+0000 | compress_modules | INFO - Quantizing model.layers.10.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:31:32.151021+0000 | compress | METRIC - time 1.05s\n",
      "2026-01-23T06:31:32.151725+0000 | compress | METRIC - error 4418.78\n",
      "2026-01-23T06:31:32.152137+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:31:32.152374+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:31:32.152796+0000 | compress_modules | INFO - Quantizing model.layers.10.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:31:33.190500+0000 | compress | METRIC - time 1.04s\n",
      "2026-01-23T06:31:33.191078+0000 | compress | METRIC - error 3775.76\n",
      "2026-01-23T06:31:33.191426+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:31:33.191646+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:31:33.192148+0000 | compress_modules | INFO - Quantizing model.layers.10.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:31:35.699959+0000 | compress | METRIC - time 2.51s\n",
      "2026-01-23T06:31:35.700763+0000 | compress | METRIC - error 152.92\n",
      "2026-01-23T06:31:35.701269+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:31:35.701526+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(11/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 170.48it/s]\n",
      "(12/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:31:49.488595+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:31:50.437303+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:31:50.437876+0000 | compress | METRIC - error 4460.34\n",
      "2026-01-23T06:31:50.438385+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:31:50.438656+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:31:50.439119+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:31:51.347386+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:31:51.347978+0000 | compress | METRIC - error 2493.98\n",
      "2026-01-23T06:31:51.348481+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:31:51.348772+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:31:51.349210+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:31:52.261268+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:31:52.261755+0000 | compress | METRIC - error 530.24\n",
      "2026-01-23T06:31:52.262212+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:31:52.262456+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:31:52.262896+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:31:53.207522+0000 | compress | METRIC - time 0.94s\n",
      "2026-01-23T06:31:53.208105+0000 | compress | METRIC - error 74.74\n",
      "2026-01-23T06:31:53.208545+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:31:53.208782+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:31:53.209193+0000 | compress_modules | INFO - Quantizing model.layers.11.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:31:54.187662+0000 | compress | METRIC - time 0.98s\n",
      "2026-01-23T06:31:54.188224+0000 | compress | METRIC - error 4576.06\n",
      "2026-01-23T06:31:54.188668+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:31:54.188901+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:31:54.189337+0000 | compress_modules | INFO - Quantizing model.layers.11.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:31:55.163161+0000 | compress | METRIC - time 0.97s\n",
      "2026-01-23T06:31:55.163746+0000 | compress | METRIC - error 4058.17\n",
      "2026-01-23T06:31:55.164178+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:31:55.164423+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:31:55.164846+0000 | compress_modules | INFO - Quantizing model.layers.11.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:31:57.777111+0000 | compress | METRIC - time 2.61s\n",
      "2026-01-23T06:31:57.778016+0000 | compress | METRIC - error 173.35\n",
      "2026-01-23T06:31:57.778462+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:31:57.778717+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(12/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.90it/s]\n",
      "(13/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:32:11.584685+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:32:12.492606+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:32:12.493137+0000 | compress | METRIC - error 6070.62\n",
      "2026-01-23T06:32:12.493601+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:32:12.493866+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:32:12.494308+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:32:13.368208+0000 | compress | METRIC - time 0.87s\n",
      "2026-01-23T06:32:13.368840+0000 | compress | METRIC - error 3595.77\n",
      "2026-01-23T06:32:13.369309+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:32:13.369697+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:32:13.370146+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:32:14.263173+0000 | compress | METRIC - time 0.89s\n",
      "2026-01-23T06:32:14.263706+0000 | compress | METRIC - error 563.08\n",
      "2026-01-23T06:32:14.264110+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:32:14.264363+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:32:14.264797+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:32:15.210334+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:32:15.210942+0000 | compress | METRIC - error 91.77\n",
      "2026-01-23T06:32:15.211389+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:32:15.211656+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:32:15.212097+0000 | compress_modules | INFO - Quantizing model.layers.12.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:32:16.218804+0000 | compress | METRIC - time 1.01s\n",
      "2026-01-23T06:32:16.219417+0000 | compress | METRIC - error 4865.57\n",
      "2026-01-23T06:32:16.219871+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:32:16.220121+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:32:16.220655+0000 | compress_modules | INFO - Quantizing model.layers.12.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:32:17.202996+0000 | compress | METRIC - time 0.98s\n",
      "2026-01-23T06:32:17.203592+0000 | compress | METRIC - error 4351.55\n",
      "2026-01-23T06:32:17.204035+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:32:17.204283+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:32:17.204722+0000 | compress_modules | INFO - Quantizing model.layers.12.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:32:19.812733+0000 | compress | METRIC - time 2.61s\n",
      "2026-01-23T06:32:19.813614+0000 | compress | METRIC - error 197.66\n",
      "2026-01-23T06:32:19.814052+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:32:19.814300+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(13/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.75it/s]\n",
      "(14/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:32:33.632586+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:32:34.540244+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:32:34.540798+0000 | compress | METRIC - error 6361.19\n",
      "2026-01-23T06:32:34.541213+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:32:34.541465+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:32:34.541901+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:32:35.409339+0000 | compress | METRIC - time 0.87s\n",
      "2026-01-23T06:32:35.409829+0000 | compress | METRIC - error 4046.89\n",
      "2026-01-23T06:32:35.410272+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:32:35.410576+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:32:35.411094+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:32:36.345293+0000 | compress | METRIC - time 0.93s\n",
      "2026-01-23T06:32:36.345870+0000 | compress | METRIC - error 650.76\n",
      "2026-01-23T06:32:36.346380+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:32:36.346653+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:32:36.347170+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:32:37.369299+0000 | compress | METRIC - time 1.02s\n",
      "2026-01-23T06:32:37.369918+0000 | compress | METRIC - error 104.51\n",
      "2026-01-23T06:32:37.370409+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:32:37.370682+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:32:37.371175+0000 | compress_modules | INFO - Quantizing model.layers.13.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:32:38.376221+0000 | compress | METRIC - time 1.00s\n",
      "2026-01-23T06:32:38.376836+0000 | compress | METRIC - error 5714.47\n",
      "2026-01-23T06:32:38.377305+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:32:38.377568+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:32:38.378007+0000 | compress_modules | INFO - Quantizing model.layers.13.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:32:39.341051+0000 | compress | METRIC - time 0.96s\n",
      "2026-01-23T06:32:39.341617+0000 | compress | METRIC - error 4815.38\n",
      "2026-01-23T06:32:39.342065+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:32:39.342309+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:32:39.342764+0000 | compress_modules | INFO - Quantizing model.layers.13.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:32:41.863532+0000 | compress | METRIC - time 2.52s\n",
      "2026-01-23T06:32:41.864517+0000 | compress | METRIC - error 253.23\n",
      "2026-01-23T06:32:41.864960+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:32:41.865201+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(14/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 170.02it/s]\n",
      "(15/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:32:55.674629+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:32:56.681123+0000 | compress | METRIC - time 1.01s\n",
      "2026-01-23T06:32:56.681730+0000 | compress | METRIC - error 6983.91\n",
      "2026-01-23T06:32:56.682215+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:32:56.682590+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:32:56.683019+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:32:57.670975+0000 | compress | METRIC - time 0.99s\n",
      "2026-01-23T06:32:57.671552+0000 | compress | METRIC - error 3310.89\n",
      "2026-01-23T06:32:57.672006+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:32:57.672259+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:32:57.672841+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:32:58.588775+0000 | compress | METRIC - time 0.92s\n",
      "2026-01-23T06:32:58.589374+0000 | compress | METRIC - error 766.75\n",
      "2026-01-23T06:32:58.589813+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:32:58.590052+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:32:58.590514+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:32:59.561311+0000 | compress | METRIC - time 0.97s\n",
      "2026-01-23T06:32:59.561943+0000 | compress | METRIC - error 130.15\n",
      "2026-01-23T06:32:59.562439+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:32:59.562811+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:32:59.563228+0000 | compress_modules | INFO - Quantizing model.layers.14.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:33:00.615440+0000 | compress | METRIC - time 1.05s\n",
      "2026-01-23T06:33:00.616039+0000 | compress | METRIC - error 6256.93\n",
      "2026-01-23T06:33:00.616526+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:33:00.616791+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:33:00.617291+0000 | compress_modules | INFO - Quantizing model.layers.14.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:33:01.579576+0000 | compress | METRIC - time 0.96s\n",
      "2026-01-23T06:33:01.580152+0000 | compress | METRIC - error 5226.71\n",
      "2026-01-23T06:33:01.580728+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:33:01.581044+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:33:01.581653+0000 | compress_modules | INFO - Quantizing model.layers.14.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:33:04.308763+0000 | compress | METRIC - time 2.73s\n",
      "2026-01-23T06:33:04.309676+0000 | compress | METRIC - error 314.39\n",
      "2026-01-23T06:33:04.310141+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:33:04.310391+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(15/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 170.61it/s]\n",
      "(16/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:33:18.106104+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:33:19.053666+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:33:19.054271+0000 | compress | METRIC - error 7261.36\n",
      "2026-01-23T06:33:19.054699+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:33:19.054934+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:33:19.055336+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:33:20.002174+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:33:20.002882+0000 | compress | METRIC - error 3772.13\n",
      "2026-01-23T06:33:20.003325+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:33:20.003559+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:33:20.003973+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:33:20.956689+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:33:20.957303+0000 | compress | METRIC - error 773.44\n",
      "2026-01-23T06:33:20.957781+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:33:20.958125+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:33:20.958536+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:33:21.862089+0000 | compress | METRIC - time 0.90s\n",
      "2026-01-23T06:33:21.862681+0000 | compress | METRIC - error 84.99\n",
      "2026-01-23T06:33:21.863115+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:33:21.863396+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:33:21.863866+0000 | compress_modules | INFO - Quantizing model.layers.15.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:33:22.876669+0000 | compress | METRIC - time 1.01s\n",
      "2026-01-23T06:33:22.877420+0000 | compress | METRIC - error 6874.94\n",
      "2026-01-23T06:33:22.877914+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:33:22.878177+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:33:22.878586+0000 | compress_modules | INFO - Quantizing model.layers.15.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:33:23.932591+0000 | compress | METRIC - time 1.05s\n",
      "2026-01-23T06:33:23.933205+0000 | compress | METRIC - error 5335.67\n",
      "2026-01-23T06:33:23.933611+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:33:23.933843+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:33:23.934232+0000 | compress_modules | INFO - Quantizing model.layers.15.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:33:26.585049+0000 | compress | METRIC - time 2.65s\n",
      "2026-01-23T06:33:26.585899+0000 | compress | METRIC - error 335.05\n",
      "2026-01-23T06:33:26.586321+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:33:26.586634+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(16/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 170.33it/s]\n",
      "(17/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:33:40.395038+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:33:41.301080+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:33:41.301623+0000 | compress | METRIC - error 7588.73\n",
      "2026-01-23T06:33:41.302058+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:33:41.302305+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:33:41.302776+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:33:42.170176+0000 | compress | METRIC - time 0.87s\n",
      "2026-01-23T06:33:42.170662+0000 | compress | METRIC - error 4240.04\n",
      "2026-01-23T06:33:42.171085+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:33:42.171334+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:33:42.171791+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:33:43.041409+0000 | compress | METRIC - time 0.87s\n",
      "2026-01-23T06:33:43.042013+0000 | compress | METRIC - error 859.71\n",
      "2026-01-23T06:33:43.042487+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:33:43.042744+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:33:43.043219+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:33:43.938396+0000 | compress | METRIC - time 0.89s\n",
      "2026-01-23T06:33:43.938943+0000 | compress | METRIC - error 60.94\n",
      "2026-01-23T06:33:43.939422+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:33:43.939678+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:33:43.940135+0000 | compress_modules | INFO - Quantizing model.layers.16.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:33:44.906497+0000 | compress | METRIC - time 0.97s\n",
      "2026-01-23T06:33:44.907088+0000 | compress | METRIC - error 7183.00\n",
      "2026-01-23T06:33:44.907547+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:33:44.907802+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:33:44.908260+0000 | compress_modules | INFO - Quantizing model.layers.16.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:33:45.874433+0000 | compress | METRIC - time 0.97s\n",
      "2026-01-23T06:33:45.874995+0000 | compress | METRIC - error 5417.14\n",
      "2026-01-23T06:33:45.875459+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:33:45.875894+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:33:45.876453+0000 | compress_modules | INFO - Quantizing model.layers.16.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:33:48.390362+0000 | compress | METRIC - time 2.51s\n",
      "2026-01-23T06:33:48.391177+0000 | compress | METRIC - error 324.47\n",
      "2026-01-23T06:33:48.391700+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:33:48.391940+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(17/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 170.30it/s]\n",
      "(18/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:34:02.205672+0000 | compress_modules | INFO - Quantizing model.layers.17.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:34:03.114473+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:34:03.115042+0000 | compress | METRIC - error 7360.72\n",
      "2026-01-23T06:34:03.115573+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:34:03.115871+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:34:03.116318+0000 | compress_modules | INFO - Quantizing model.layers.17.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:34:04.111544+0000 | compress | METRIC - time 0.99s\n",
      "2026-01-23T06:34:04.112137+0000 | compress | METRIC - error 3976.41\n",
      "2026-01-23T06:34:04.112669+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:34:04.113043+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:34:04.113481+0000 | compress_modules | INFO - Quantizing model.layers.17.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:34:05.073687+0000 | compress | METRIC - time 0.96s\n",
      "2026-01-23T06:34:05.074292+0000 | compress | METRIC - error 841.28\n",
      "2026-01-23T06:34:05.074765+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:34:05.075033+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:34:05.075524+0000 | compress_modules | INFO - Quantizing model.layers.17.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:34:05.965305+0000 | compress | METRIC - time 0.89s\n",
      "2026-01-23T06:34:05.965852+0000 | compress | METRIC - error 60.11\n",
      "2026-01-23T06:34:05.966297+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:34:05.966562+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:34:05.966989+0000 | compress_modules | INFO - Quantizing model.layers.17.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:34:06.950184+0000 | compress | METRIC - time 0.98s\n",
      "2026-01-23T06:34:06.950733+0000 | compress | METRIC - error 7664.76\n",
      "2026-01-23T06:34:06.951184+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:34:06.951495+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:34:06.951982+0000 | compress_modules | INFO - Quantizing model.layers.17.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:34:07.922681+0000 | compress | METRIC - time 0.97s\n",
      "2026-01-23T06:34:07.923242+0000 | compress | METRIC - error 5682.24\n",
      "2026-01-23T06:34:07.923739+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:34:07.924105+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:34:07.924520+0000 | compress_modules | INFO - Quantizing model.layers.17.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:34:10.509070+0000 | compress | METRIC - time 2.58s\n",
      "2026-01-23T06:34:10.509931+0000 | compress | METRIC - error 350.36\n",
      "2026-01-23T06:34:10.510425+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:34:10.510890+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(18/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.37it/s]\n",
      "(19/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:34:24.350410+0000 | compress_modules | INFO - Quantizing model.layers.18.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:34:25.270986+0000 | compress | METRIC - time 0.92s\n",
      "2026-01-23T06:34:25.271543+0000 | compress | METRIC - error 8071.42\n",
      "2026-01-23T06:34:25.271960+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:34:25.272179+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:34:25.272684+0000 | compress_modules | INFO - Quantizing model.layers.18.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:34:26.144777+0000 | compress | METRIC - time 0.87s\n",
      "2026-01-23T06:34:26.145431+0000 | compress | METRIC - error 4455.64\n",
      "2026-01-23T06:34:26.146031+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:34:26.146323+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:34:26.146962+0000 | compress_modules | INFO - Quantizing model.layers.18.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:34:27.042392+0000 | compress | METRIC - time 0.90s\n",
      "2026-01-23T06:34:27.042916+0000 | compress | METRIC - error 1026.81\n",
      "2026-01-23T06:34:27.043352+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:34:27.043619+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:34:27.044083+0000 | compress_modules | INFO - Quantizing model.layers.18.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:34:27.987379+0000 | compress | METRIC - time 0.94s\n",
      "2026-01-23T06:34:27.988005+0000 | compress | METRIC - error 68.59\n",
      "2026-01-23T06:34:27.988539+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:34:27.988787+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:34:27.989182+0000 | compress_modules | INFO - Quantizing model.layers.18.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:34:28.959320+0000 | compress | METRIC - time 0.97s\n",
      "2026-01-23T06:34:28.959901+0000 | compress | METRIC - error 8164.10\n",
      "2026-01-23T06:34:28.960322+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:34:28.960567+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:34:28.961065+0000 | compress_modules | INFO - Quantizing model.layers.18.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:34:29.933239+0000 | compress | METRIC - time 0.97s\n",
      "2026-01-23T06:34:29.933844+0000 | compress | METRIC - error 6180.44\n",
      "2026-01-23T06:34:29.934279+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:34:29.934539+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:34:29.935033+0000 | compress_modules | INFO - Quantizing model.layers.18.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:34:32.521371+0000 | compress | METRIC - time 2.59s\n",
      "2026-01-23T06:34:32.522276+0000 | compress | METRIC - error 386.90\n",
      "2026-01-23T06:34:32.522784+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:34:32.523054+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(19/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.61it/s]\n",
      "(20/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:34:46.368254+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:34:47.352659+0000 | compress | METRIC - time 0.98s\n",
      "2026-01-23T06:34:47.353254+0000 | compress | METRIC - error 7542.83\n",
      "2026-01-23T06:34:47.353927+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:34:47.354216+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:34:47.354756+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:34:48.295142+0000 | compress | METRIC - time 0.94s\n",
      "2026-01-23T06:34:48.295792+0000 | compress | METRIC - error 4344.13\n",
      "2026-01-23T06:34:48.296207+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:34:48.296457+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:34:48.296915+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:34:49.162292+0000 | compress | METRIC - time 0.87s\n",
      "2026-01-23T06:34:49.162855+0000 | compress | METRIC - error 1053.46\n",
      "2026-01-23T06:34:49.163278+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:34:49.163591+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:34:49.163974+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:34:50.077627+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:34:50.078364+0000 | compress | METRIC - error 91.86\n",
      "2026-01-23T06:34:50.078767+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:34:50.078991+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:34:50.079392+0000 | compress_modules | INFO - Quantizing model.layers.19.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:34:51.057885+0000 | compress | METRIC - time 0.98s\n",
      "2026-01-23T06:34:51.058484+0000 | compress | METRIC - error 8700.62\n",
      "2026-01-23T06:34:51.058867+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:34:51.059100+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:34:51.059515+0000 | compress_modules | INFO - Quantizing model.layers.19.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:34:52.032803+0000 | compress | METRIC - time 0.97s\n",
      "2026-01-23T06:34:52.033450+0000 | compress | METRIC - error 6685.36\n",
      "2026-01-23T06:34:52.033878+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:34:52.034099+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:34:52.034506+0000 | compress_modules | INFO - Quantizing model.layers.19.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:34:54.761144+0000 | compress | METRIC - time 2.73s\n",
      "2026-01-23T06:34:54.762099+0000 | compress | METRIC - error 464.40\n",
      "2026-01-23T06:34:54.762526+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:34:54.762789+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(20/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.32it/s]\n",
      "(21/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:35:08.597887+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:35:09.545906+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:35:09.546467+0000 | compress | METRIC - error 7857.23\n",
      "2026-01-23T06:35:09.546919+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:35:09.547174+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:35:09.547653+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:35:10.456211+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:35:10.456782+0000 | compress | METRIC - error 4696.80\n",
      "2026-01-23T06:35:10.457225+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:35:10.457487+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:35:10.457955+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:35:11.367084+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:35:11.367645+0000 | compress | METRIC - error 1266.66\n",
      "2026-01-23T06:35:11.367973+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:35:11.368191+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:35:11.368586+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:35:12.353390+0000 | compress | METRIC - time 0.98s\n",
      "2026-01-23T06:35:12.354115+0000 | compress | METRIC - error 76.78\n",
      "2026-01-23T06:35:12.354601+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:35:12.354833+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:35:12.355230+0000 | compress_modules | INFO - Quantizing model.layers.20.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:35:13.425394+0000 | compress | METRIC - time 1.07s\n",
      "2026-01-23T06:35:13.426020+0000 | compress | METRIC - error 8592.85\n",
      "2026-01-23T06:35:13.426607+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:35:13.426904+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:35:13.427397+0000 | compress_modules | INFO - Quantizing model.layers.20.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:35:14.470240+0000 | compress | METRIC - time 1.04s\n",
      "2026-01-23T06:35:14.470849+0000 | compress | METRIC - error 6903.70\n",
      "2026-01-23T06:35:14.471190+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:35:14.471469+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:35:14.472011+0000 | compress_modules | INFO - Quantizing model.layers.20.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:35:17.040374+0000 | compress | METRIC - time 2.57s\n",
      "2026-01-23T06:35:17.041307+0000 | compress | METRIC - error 468.37\n",
      "2026-01-23T06:35:17.041870+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:35:17.042286+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(21/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.80it/s]\n",
      "(22/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:35:30.869084+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:35:31.789492+0000 | compress | METRIC - time 0.92s\n",
      "2026-01-23T06:35:31.790033+0000 | compress | METRIC - error 7752.72\n",
      "2026-01-23T06:35:31.790492+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:35:31.790766+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:35:31.791217+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:35:32.740740+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:35:32.741462+0000 | compress | METRIC - error 4578.25\n",
      "2026-01-23T06:35:32.741987+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:35:32.742352+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:35:32.742777+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:35:33.691040+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:35:33.691592+0000 | compress | METRIC - error 1635.25\n",
      "2026-01-23T06:35:33.692052+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:35:33.692296+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:35:33.692744+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:35:34.605340+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:35:34.605978+0000 | compress | METRIC - error 88.50\n",
      "2026-01-23T06:35:34.606455+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:35:34.606785+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:35:34.607245+0000 | compress_modules | INFO - Quantizing model.layers.21.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:35:35.577161+0000 | compress | METRIC - time 0.97s\n",
      "2026-01-23T06:35:35.577721+0000 | compress | METRIC - error 9337.83\n",
      "2026-01-23T06:35:35.578178+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:35:35.578421+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:35:35.578908+0000 | compress_modules | INFO - Quantizing model.layers.21.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:35:36.548460+0000 | compress | METRIC - time 0.97s\n",
      "2026-01-23T06:35:36.549044+0000 | compress | METRIC - error 7440.41\n",
      "2026-01-23T06:35:36.549492+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:35:36.549748+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:35:36.550165+0000 | compress_modules | INFO - Quantizing model.layers.21.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:35:39.297397+0000 | compress | METRIC - time 2.75s\n",
      "2026-01-23T06:35:39.298298+0000 | compress | METRIC - error 500.13\n",
      "2026-01-23T06:35:39.298740+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:35:39.298988+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(22/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.20it/s]\n",
      "(23/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:35:53.132664+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:35:54.081266+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:35:54.081813+0000 | compress | METRIC - error 7924.70\n",
      "2026-01-23T06:35:54.082216+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:35:54.082598+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:35:54.082991+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:35:54.997685+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:35:54.998289+0000 | compress | METRIC - error 4512.09\n",
      "2026-01-23T06:35:54.998723+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:35:54.999037+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:35:54.999409+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:35:55.913652+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:35:55.914207+0000 | compress | METRIC - error 1693.76\n",
      "2026-01-23T06:35:55.914683+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:35:55.914942+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:35:55.915488+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:35:56.852679+0000 | compress | METRIC - time 0.94s\n",
      "2026-01-23T06:35:56.853252+0000 | compress | METRIC - error 70.81\n",
      "2026-01-23T06:35:56.853696+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:35:56.853938+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:35:56.854356+0000 | compress_modules | INFO - Quantizing model.layers.22.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:35:57.863824+0000 | compress | METRIC - time 1.01s\n",
      "2026-01-23T06:35:57.864429+0000 | compress | METRIC - error 10121.54\n",
      "2026-01-23T06:35:57.864839+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:35:57.865074+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:35:57.865473+0000 | compress_modules | INFO - Quantizing model.layers.22.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:35:58.919987+0000 | compress | METRIC - time 1.05s\n",
      "2026-01-23T06:35:58.920612+0000 | compress | METRIC - error 8032.20\n",
      "2026-01-23T06:35:58.921092+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:35:58.921378+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:35:58.921836+0000 | compress_modules | INFO - Quantizing model.layers.22.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:36:01.501261+0000 | compress | METRIC - time 2.58s\n",
      "2026-01-23T06:36:01.502229+0000 | compress | METRIC - error 561.57\n",
      "2026-01-23T06:36:01.502685+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:36:01.502947+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(23/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.69it/s]\n",
      "(24/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:36:15.346299+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:36:16.256139+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:36:16.256715+0000 | compress | METRIC - error 7725.31\n",
      "2026-01-23T06:36:16.257144+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:36:16.257400+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:36:16.257838+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:36:17.129875+0000 | compress | METRIC - time 0.87s\n",
      "2026-01-23T06:36:17.130391+0000 | compress | METRIC - error 4723.49\n",
      "2026-01-23T06:36:17.130849+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:36:17.131108+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:36:17.131592+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:36:18.002368+0000 | compress | METRIC - time 0.87s\n",
      "2026-01-23T06:36:18.002930+0000 | compress | METRIC - error 1637.22\n",
      "2026-01-23T06:36:18.003497+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:36:18.003800+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:36:18.004274+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:36:18.914940+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:36:18.915533+0000 | compress | METRIC - error 111.33\n",
      "2026-01-23T06:36:18.916039+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:36:18.916401+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:36:18.916876+0000 | compress_modules | INFO - Quantizing model.layers.23.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:36:19.968428+0000 | compress | METRIC - time 1.05s\n",
      "2026-01-23T06:36:19.969090+0000 | compress | METRIC - error 11526.76\n",
      "2026-01-23T06:36:19.969571+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:36:19.969885+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:36:19.970235+0000 | compress_modules | INFO - Quantizing model.layers.23.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:36:21.041245+0000 | compress | METRIC - time 1.07s\n",
      "2026-01-23T06:36:21.041835+0000 | compress | METRIC - error 8747.33\n",
      "2026-01-23T06:36:21.042291+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:36:21.042582+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:36:21.043050+0000 | compress_modules | INFO - Quantizing model.layers.23.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:36:23.638059+0000 | compress | METRIC - time 2.59s\n",
      "2026-01-23T06:36:23.639322+0000 | compress | METRIC - error 650.32\n",
      "2026-01-23T06:36:23.639770+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:36:23.640026+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(24/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.00it/s]\n",
      "(25/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:36:37.477509+0000 | compress_modules | INFO - Quantizing model.layers.24.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:36:38.385870+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:36:38.386453+0000 | compress | METRIC - error 8377.51\n",
      "2026-01-23T06:36:38.386904+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:36:38.387147+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:36:38.387569+0000 | compress_modules | INFO - Quantizing model.layers.24.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:36:39.272581+0000 | compress | METRIC - time 0.88s\n",
      "2026-01-23T06:36:39.273118+0000 | compress | METRIC - error 5162.77\n",
      "2026-01-23T06:36:39.273552+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:36:39.273867+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:36:39.274239+0000 | compress_modules | INFO - Quantizing model.layers.24.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:36:40.180562+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:36:40.181200+0000 | compress | METRIC - error 2331.51\n",
      "2026-01-23T06:36:40.181640+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:36:40.181887+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:36:40.182302+0000 | compress_modules | INFO - Quantizing model.layers.24.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:36:41.126611+0000 | compress | METRIC - time 0.94s\n",
      "2026-01-23T06:36:41.127196+0000 | compress | METRIC - error 163.39\n",
      "2026-01-23T06:36:41.127696+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:36:41.128003+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:36:41.128503+0000 | compress_modules | INFO - Quantizing model.layers.24.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:36:42.116658+0000 | compress | METRIC - time 0.99s\n",
      "2026-01-23T06:36:42.117276+0000 | compress | METRIC - error 13130.95\n",
      "2026-01-23T06:36:42.117707+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:36:42.117949+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:36:42.118367+0000 | compress_modules | INFO - Quantizing model.layers.24.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:36:43.098000+0000 | compress | METRIC - time 0.98s\n",
      "2026-01-23T06:36:43.098597+0000 | compress | METRIC - error 9810.08\n",
      "2026-01-23T06:36:43.099034+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:36:43.099280+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:36:43.099746+0000 | compress_modules | INFO - Quantizing model.layers.24.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:36:45.656398+0000 | compress | METRIC - time 2.56s\n",
      "2026-01-23T06:36:45.657202+0000 | compress | METRIC - error 775.97\n",
      "2026-01-23T06:36:45.657644+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:36:45.657888+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(25/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.47it/s]\n",
      "(26/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:36:59.511915+0000 | compress_modules | INFO - Quantizing model.layers.25.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:37:00.420959+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:37:00.421611+0000 | compress | METRIC - error 8701.06\n",
      "2026-01-23T06:37:00.422020+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:37:00.422261+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:37:00.422719+0000 | compress_modules | INFO - Quantizing model.layers.25.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:37:01.287776+0000 | compress | METRIC - time 0.86s\n",
      "2026-01-23T06:37:01.288296+0000 | compress | METRIC - error 4485.78\n",
      "2026-01-23T06:37:01.288742+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:37:01.288977+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:37:01.289397+0000 | compress_modules | INFO - Quantizing model.layers.25.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:37:02.160302+0000 | compress | METRIC - time 0.87s\n",
      "2026-01-23T06:37:02.161060+0000 | compress | METRIC - error 2226.64\n",
      "2026-01-23T06:37:02.161498+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:37:02.161738+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:37:02.162175+0000 | compress_modules | INFO - Quantizing model.layers.25.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:37:03.065891+0000 | compress | METRIC - time 0.90s\n",
      "2026-01-23T06:37:03.066478+0000 | compress | METRIC - error 142.34\n",
      "2026-01-23T06:37:03.066927+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:37:03.067171+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:37:03.067605+0000 | compress_modules | INFO - Quantizing model.layers.25.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:37:04.037857+0000 | compress | METRIC - time 0.97s\n",
      "2026-01-23T06:37:04.038482+0000 | compress | METRIC - error 14190.17\n",
      "2026-01-23T06:37:04.038899+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:37:04.039136+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:37:04.039574+0000 | compress_modules | INFO - Quantizing model.layers.25.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:37:05.090308+0000 | compress | METRIC - time 1.05s\n",
      "2026-01-23T06:37:05.090957+0000 | compress | METRIC - error 10616.38\n",
      "2026-01-23T06:37:05.091445+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:37:05.091747+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:37:05.092196+0000 | compress_modules | INFO - Quantizing model.layers.25.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:37:07.684448+0000 | compress | METRIC - time 2.59s\n",
      "2026-01-23T06:37:07.685325+0000 | compress | METRIC - error 968.97\n",
      "2026-01-23T06:37:07.685760+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:37:07.685996+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(26/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.33it/s]\n",
      "(27/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:37:21.528246+0000 | compress_modules | INFO - Quantizing model.layers.26.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:37:22.480015+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:37:22.480644+0000 | compress | METRIC - error 7487.92\n",
      "2026-01-23T06:37:22.481104+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:37:22.481444+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:37:22.481849+0000 | compress_modules | INFO - Quantizing model.layers.26.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:37:23.376929+0000 | compress | METRIC - time 0.89s\n",
      "2026-01-23T06:37:23.377567+0000 | compress | METRIC - error 4801.38\n",
      "2026-01-23T06:37:23.378003+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:37:23.378255+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:37:23.378724+0000 | compress_modules | INFO - Quantizing model.layers.26.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:37:24.326907+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:37:24.327564+0000 | compress | METRIC - error 2863.52\n",
      "2026-01-23T06:37:24.328012+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:37:24.328276+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:37:24.328726+0000 | compress_modules | INFO - Quantizing model.layers.26.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:37:25.325484+0000 | compress | METRIC - time 1.00s\n",
      "2026-01-23T06:37:25.326113+0000 | compress | METRIC - error 292.76\n",
      "2026-01-23T06:37:25.326544+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:37:25.326812+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:37:25.327227+0000 | compress_modules | INFO - Quantizing model.layers.26.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:37:26.375302+0000 | compress | METRIC - time 1.05s\n",
      "2026-01-23T06:37:26.375955+0000 | compress | METRIC - error 14938.59\n",
      "2026-01-23T06:37:26.376434+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:37:26.376712+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:37:26.377165+0000 | compress_modules | INFO - Quantizing model.layers.26.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:37:27.404764+0000 | compress | METRIC - time 1.03s\n",
      "2026-01-23T06:37:27.405362+0000 | compress | METRIC - error 11047.92\n",
      "2026-01-23T06:37:27.405937+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:37:27.406234+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:37:27.406888+0000 | compress_modules | INFO - Quantizing model.layers.26.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:37:29.964623+0000 | compress | METRIC - time 2.56s\n",
      "2026-01-23T06:37:29.965562+0000 | compress | METRIC - error 1288.94\n",
      "2026-01-23T06:37:29.966148+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:37:29.966467+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(27/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 170.03it/s]\n",
      "(28/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:37:43.795586+0000 | compress_modules | INFO - Quantizing model.layers.27.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:37:44.706367+0000 | compress | METRIC - time 0.91s\n",
      "2026-01-23T06:37:44.706972+0000 | compress | METRIC - error 6126.65\n",
      "2026-01-23T06:37:44.707407+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:37:44.707677+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:37:44.708105+0000 | compress_modules | INFO - Quantizing model.layers.27.self_attn.k_proj using 512 samples\n",
      "2026-01-23T06:37:45.661212+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:37:45.661841+0000 | compress | METRIC - error 3450.79\n",
      "2026-01-23T06:37:45.662323+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:37:45.662659+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:37:45.663247+0000 | compress_modules | INFO - Quantizing model.layers.27.self_attn.v_proj using 512 samples\n",
      "2026-01-23T06:37:46.612705+0000 | compress | METRIC - time 0.95s\n",
      "2026-01-23T06:37:46.613397+0000 | compress | METRIC - error 1895.07\n",
      "2026-01-23T06:37:46.613772+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:37:46.613990+0000 | compress | METRIC - Compressed module size: 6.365184 MB\n",
      "2026-01-23T06:37:46.614454+0000 | compress_modules | INFO - Quantizing model.layers.27.self_attn.o_proj using 512 samples\n",
      "2026-01-23T06:37:47.598360+0000 | compress | METRIC - time 0.98s\n",
      "2026-01-23T06:37:47.599104+0000 | compress | METRIC - error 649.41\n",
      "2026-01-23T06:37:47.599442+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-23T06:37:47.599687+0000 | compress | METRIC - Compressed module size: 19.095552 MB\n",
      "2026-01-23T06:37:47.600086+0000 | compress_modules | INFO - Quantizing model.layers.27.mlp.gate_proj using 512 samples\n",
      "2026-01-23T06:37:48.650658+0000 | compress | METRIC - time 1.05s\n",
      "2026-01-23T06:37:48.651235+0000 | compress | METRIC - error 13985.18\n",
      "2026-01-23T06:37:48.651672+0000 | compress | METRIC - GPU 0 | usage: 12.25% | total memory: 25 GB\n",
      "2026-01-23T06:37:48.651914+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:37:48.652334+0000 | compress_modules | INFO - Quantizing model.layers.27.mlp.up_proj using 512 samples\n",
      "2026-01-23T06:37:49.633867+0000 | compress | METRIC - time 0.98s\n",
      "2026-01-23T06:37:49.634458+0000 | compress | METRIC - error 11660.71\n",
      "2026-01-23T06:37:49.634874+0000 | compress | METRIC - GPU 0 | usage: 12.26% | total memory: 25 GB\n",
      "2026-01-23T06:37:49.635111+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n",
      "2026-01-23T06:37:49.635525+0000 | compress_modules | INFO - Quantizing model.layers.27.mlp.down_proj using 512 samples\n",
      "2026-01-23T06:37:52.247613+0000 | compress | METRIC - time 2.61s\n",
      "2026-01-23T06:37:52.248531+0000 | compress | METRIC - error 2853.07\n",
      "2026-01-23T06:37:52.248967+0000 | compress | METRIC - GPU 0 | usage: 13.30% | total memory: 25 GB\n",
      "2026-01-23T06:37:52.249217+0000 | compress | METRIC - Compressed module size: 50.921472 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(28/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.96it/s]\n",
      "(29/29): Calibrating: 100%|██████████| 512/512 [00:00<00:00, 1279.18it/s]\n",
      "(29/29): Propagating: 100%|██████████| 512/512 [00:00<00:00, 1444.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:37:56.158784+0000 | finalize | INFO - Compression lifecycle finalized for 1 modifiers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-23T06:37:56.188614+0000 | get_model_compressor | INFO - skip_sparsity_compression_stats set to True. Skipping sparsity compression statistic calculations. No sparsity compressor will be applied.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compressing model: 196it [00:05, 36.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 3072)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "          (k_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply quantization with GPTQ recipe\n",
    "from llmcompressor import oneshot\n",
    "from llmcompressor.modifiers.quantization import GPTQModifier\n",
    "\n",
    "# Configure the quantization algorithm to run.\n",
    "recipe = GPTQModifier(targets=\"Linear\", scheme=\"W4A16\", ignore=[\"lm_head\"])\n",
    "\n",
    "# Save dir name\n",
    "SAVE_DIR = MODEL_ID.rstrip(\"/\").split(\"/\")[-1] + \"-W4A16-G128\"\n",
    "\n",
    "# Apply quantization.\n",
    "oneshot(\n",
    "    model=model, dataset=ds,\n",
    "    recipe=recipe,\n",
    "    max_seq_length=MAX_SEQUENCE_LENGTH,\n",
    "    num_calibration_samples=NUM_CALIBRATION_SAMPLES,\n",
    "    output_dir=SAVE_DIR,    # Tokenizer automatically saved together\n",
    ")\n",
    "\n",
    "# # Save to disk compressed.\n",
    "# model.save_pretrained(SAVE_DIR, save_compressed=True)\n",
    "# tokenizer.save_pretrained(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2de8976",
   "metadata": {},
   "source": [
    "결과: 6.43Gb -> 2.82Gb로 약 44% 압축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca07c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need.\n",
    "!pip install -U lm_eval       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70e5c5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-23 06:38:44] WARNING __main__.py:369:  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
      "[2026-01-23 06:38:44] INFO __main__.py:465: Selected Tasks: ['gsm8k']\n",
      "[2026-01-23 06:38:44] WARNING evaluator.py:172: pretrained=pretrained=./Llama-3.2-3B-Instruct-W4A16-G128,add_bos_token=true appears to be an instruct or chat variant but chat template is\n",
      "        not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).\n",
      "[2026-01-23 06:38:44] INFO evaluator.py:202: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "[2026-01-23 06:38:44] INFO evaluator.py:240: Initializing vllm model, with arguments: {'pretrained': './Llama-3.2-3B-Instruct-W4A16-G128', 'add_bos_token': True}\n",
      "\u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:44\u001b[0m \u001b[90m[utils.py:263]\u001b[0m non-default args: {'seed': 1234, 'disable_log_stats': True, 'model': './Llama-3.2-3B-Instruct-W4A16-G128'}\n",
      "\u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:44\u001b[0m \u001b[90m[model.py:530]\u001b[0m Resolved architecture: LlamaForCausalLM\n",
      "\u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:44\u001b[0m \u001b[90m[model.py:1545]\u001b[0m Using max model len 131072\n",
      "\u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:45\u001b[0m \u001b[90m[scheduler.py:229]\u001b[0m Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "\u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:45\u001b[0m \u001b[90m[vllm.py:630]\u001b[0m Asynchronous scheduling is enabled.\n",
      "\u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:45\u001b[0m \u001b[90m[vllm.py:637]\u001b[0m Disabling NCCL for DP synchronization when using async scheduling.\n",
      "The tokenizer you are loading from './Llama-3.2-3B-Instruct-W4A16-G128' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=208892)\u001b[0;0m \u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:46\u001b[0m \u001b[90m[core.py:97]\u001b[0m Initializing a V1 LLM engine (v0.14.0) with config: model='./Llama-3.2-3B-Instruct-W4A16-G128', speculative_config=None, tokenizer='./Llama-3.2-3B-Instruct-W4A16-G128', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=compressed-tensors, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=1234, served_model_name=./Llama-3.2-3B-Instruct-W4A16-G128, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [8192], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 512, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}\n",
      "\u001b[0;36m(EngineCore_DP0 pid=208892)\u001b[0;0m \u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:46\u001b[0m \u001b[90m[parallel_state.py:1214]\u001b[0m world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://172.17.0.3:47435 backend=nccl\n",
      "\u001b[0;36m(EngineCore_DP0 pid=208892)\u001b[0;0m \u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:46\u001b[0m \u001b[90m[parallel_state.py:1425]\u001b[0m rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank N/A\n",
      "\u001b[0;36m(EngineCore_DP0 pid=208892)\u001b[0;0m \u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:47\u001b[0m \u001b[90m[gpu_model_runner.py:3808]\u001b[0m Starting to load model ./Llama-3.2-3B-Instruct-W4A16-G128...\n",
      "\u001b[0;36m(EngineCore_DP0 pid=208892)\u001b[0;0m \u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:47\u001b[0m \u001b[90m[compressed_tensors_wNa16.py:114]\u001b[0m Using MarlinLinearKernel for CompressedTensorsWNA16\n",
      "\u001b[0;36m(EngineCore_DP0 pid=208892)\u001b[0;0m \u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:47\u001b[0m \u001b[90m[cuda.py:351]\u001b[0m Using FLASH_ATTN attention backend out of potential backends: ('FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION')\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.42it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.42it/s]\n",
      "\u001b[0;36m(EngineCore_DP0 pid=208892)\u001b[0;0m \n",
      "\u001b[0;36m(EngineCore_DP0 pid=208892)\u001b[0;0m \u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:48\u001b[0m \u001b[90m[default_loader.py:291]\u001b[0m Loading weights took 0.36 seconds\n",
      "\u001b[0;36m(EngineCore_DP0 pid=208892)\u001b[0;0m \u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:48\u001b[0m \u001b[90m[gpu_model_runner.py:3905]\u001b[0m Model loading took 2.13 GiB memory and 0.722318 seconds\n",
      "\u001b[0;36m(EngineCore_DP0 pid=208892)\u001b[0;0m \u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:54\u001b[0m \u001b[90m[backends.py:644]\u001b[0m Using cache directory: /root/.cache/vllm/torch_compile_cache/9b96f33526/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[0;36m(EngineCore_DP0 pid=208892)\u001b[0;0m \u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:54\u001b[0m \u001b[90m[backends.py:704]\u001b[0m Dynamo bytecode transform time: 5.30 s\n",
      "\u001b[0;36m(EngineCore_DP0 pid=208892)\u001b[0;0m \u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:57\u001b[0m \u001b[90m[backends.py:226]\u001b[0m Directly load the compiled graph(s) for compile range (1, 8192) from the cache, took 0.754 s\n",
      "\u001b[0;36m(EngineCore_DP0 pid=208892)\u001b[0;0m \u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:57\u001b[0m \u001b[90m[monitor.py:34]\u001b[0m torch.compile takes 6.05 s in total\n",
      "\u001b[0;36m(EngineCore_DP0 pid=208892)\u001b[0;0m \u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:58\u001b[0m \u001b[90m[gpu_worker.py:358]\u001b[0m Available KV cache memory: 17.83 GiB\n",
      "\u001b[0;36m(EngineCore_DP0 pid=208892)\u001b[0;0m \u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:58\u001b[0m \u001b[90m[kv_cache_utils.py:1305]\u001b[0m GPU KV cache size: 166,928 tokens\n",
      "\u001b[0;36m(EngineCore_DP0 pid=208892)\u001b[0;0m \u001b[32mINFO\u001b[0m \u001b[90m01-23 06:38:58\u001b[0m \u001b[90m[kv_cache_utils.py:1310]\u001b[0m Maximum concurrency for 131,072 tokens per request: 1.27x\n",
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|█| 51/51 [00:01<00\n",
      "Capturing CUDA graphs (decode, FULL): 100%|█████| 35/35 [00:01<00:00, 34.34it/s]\n",
      "\u001b[0;36m(EngineCore_DP0 pid=208892)\u001b[0;0m \u001b[32mINFO\u001b[0m \u001b[90m01-23 06:39:01\u001b[0m \u001b[90m[gpu_model_runner.py:4856]\u001b[0m Graph capturing finished in 3 secs, took 0.50 GiB\n",
      "\u001b[0;36m(EngineCore_DP0 pid=208892)\u001b[0;0m \u001b[32mINFO\u001b[0m \u001b[90m01-23 06:39:01\u001b[0m \u001b[90m[core.py:273]\u001b[0m init engine (profile, create kv cache, warmup model) took 13.13 seconds\n",
      "\u001b[32mINFO\u001b[0m \u001b[90m01-23 06:39:02\u001b[0m \u001b[90m[llm.py:347]\u001b[0m Supported tasks: ['generate']\n",
      "The tokenizer you are loading from './Llama-3.2-3B-Instruct-W4A16-G128' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
      "The tokenizer you are loading from './Llama-3.2-3B-Instruct-W4A16-G128' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
      "[2026-01-23 06:39:08] INFO __init__.py:695: Selected tasks:\n",
      "[2026-01-23 06:39:08] INFO __init__.py:686: Task: gsm8k (gsm8k/gsm8k.yaml)\n",
      "[2026-01-23 06:39:08] INFO evaluator.py:305: gsm8k: Using gen_kwargs: {'until': ['Question:', '</s>', '<|im_end|>'], 'do_sample': False, 'temperature': 0.0}\n",
      "[2026-01-23 06:39:08] WARNING evaluator.py:324: Overwriting default num_fewshot of gsm8k from 5 to 5\n",
      "[2026-01-23 06:39:08] INFO task.py:434: Building contexts for gsm8k on rank 0...\n",
      "100%|████████████████████████████████████████| 250/250 [00:00<00:00, 457.51it/s]\n",
      "[2026-01-23 06:39:09] INFO evaluator.py:574: Running generate_until requests\n",
      "Running generate_until requests:   0%|                  | 0/250 [00:00<?, ?it/s]\n",
      "Adding requests: 100%|██████████████████████| 250/250 [00:00<00:00, 7787.01it/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%| | 0/250 [00:00<?, ?it/s, est. speed input: 0.00 toks/s,\u001b[A\n",
      "Processed prompts:   0%| | 1/250 [00:15<1:05:04, 15.68s/it, est. speed input: 71\u001b[A\n",
      "Processed prompts:   1%| | 2/250 [00:16<29:11,  7.06s/it, est. speed input: 134.\u001b[A\n",
      "Processed prompts:   2%| | 5/250 [00:17<08:53,  2.18s/it, est. speed input: 302.\u001b[A\n",
      "Processed prompts:   3%| | 8/250 [00:18<04:46,  1.19s/it, est. speed input: 478.\u001b[A\n",
      "Processed prompts:   4%| | 11/250 [00:18<02:51,  1.39it/s, est. speed input: 628\u001b[A\n",
      "Processed prompts:   6%| | 15/250 [00:18<01:47,  2.18it/s, est. speed input: 811\u001b[A\n",
      "Processed prompts:   7%| | 17/250 [00:19<01:31,  2.55it/s, est. speed input: 891\u001b[A\n",
      "Processed prompts:   7%| | 18/250 [00:19<01:25,  2.70it/s, est. speed input: 934\u001b[A\n",
      "Processed prompts:  10%| | 25/250 [00:19<00:40,  5.54it/s, est. speed input: 127\u001b[A\n",
      "Processed prompts:  11%| | 27/250 [00:20<00:39,  5.69it/s, est. speed input: 136\u001b[A\n",
      "Processed prompts:  11%| | 28/250 [00:20<00:51,  4.34it/s, est. speed input: 136\u001b[A\n",
      "Processed prompts:  12%| | 30/250 [00:21<00:48,  4.52it/s, est. speed input: 143\u001b[A\n",
      "Processed prompts:  13%|▏| 32/250 [00:21<00:40,  5.41it/s, est. speed input: 150\u001b[A\n",
      "Processed prompts:  14%|▏| 35/250 [00:21<00:32,  6.59it/s, est. speed input: 160\u001b[A\n",
      "Processed prompts:  14%|▏| 36/250 [00:21<00:39,  5.44it/s, est. speed input: 162\u001b[A\n",
      "Processed prompts:  16%|▏| 39/250 [00:22<00:29,  7.07it/s, est. speed input: 172\u001b[A\n",
      "Processed prompts:  16%|▏| 40/250 [00:22<00:32,  6.39it/s, est. speed input: 174\u001b[A\n",
      "Processed prompts:  17%|▏| 43/250 [00:22<00:28,  7.22it/s, est. speed input: 184\u001b[A\n",
      "Processed prompts:  19%|▏| 47/250 [00:23<00:22,  8.98it/s, est. speed input: 200\u001b[A\n",
      "Processed prompts:  20%|▏| 49/250 [00:23<00:24,  8.31it/s, est. speed input: 205\u001b[A\n",
      "Processed prompts:  20%|▏| 50/250 [00:23<00:39,  5.06it/s, est. speed input: 204\u001b[A\n",
      "Processed prompts:  22%|▏| 54/250 [00:24<00:25,  7.56it/s, est. speed input: 218\u001b[A\n",
      "Processed prompts:  22%|▏| 56/250 [00:24<00:27,  6.96it/s, est. speed input: 223\u001b[A\n",
      "Processed prompts:  25%|▏| 62/250 [00:25<00:25,  7.45it/s, est. speed input: 240\u001b[A\n",
      "Processed prompts:  25%|▎| 63/250 [00:25<00:29,  6.41it/s, est. speed input: 241\u001b[A\n",
      "Processed prompts:  26%|▎| 66/250 [00:25<00:22,  8.10it/s, est. speed input: 250\u001b[A\n",
      "Processed prompts:  28%|▎| 69/250 [00:25<00:18,  9.83it/s, est. speed input: 260\u001b[A\n",
      "Processed prompts:  28%|▎| 71/250 [00:26<00:19,  9.04it/s, est. speed input: 264\u001b[A\n",
      "Processed prompts:  30%|▎| 74/250 [00:26<00:20,  8.52it/s, est. speed input: 271\u001b[A\n",
      "Processed prompts:  30%|▎| 76/250 [00:26<00:21,  7.99it/s, est. speed input: 274\u001b[A\n",
      "Processed prompts:  33%|▎| 82/250 [00:27<00:12, 13.63it/s, est. speed input: 296\u001b[A\n",
      "Processed prompts:  36%|▎| 90/250 [00:27<00:07, 20.70it/s, est. speed input: 321\u001b[A\n",
      "Processed prompts:  38%|▍| 96/250 [00:27<00:05, 25.68it/s, est. speed input: 339\u001b[A\n",
      "Processed prompts:  41%|▍| 102/250 [00:27<00:04, 30.41it/s, est. speed input: 35\u001b[A\n",
      "Processed prompts:  42%|▍| 106/250 [00:27<00:04, 31.02it/s, est. speed input: 36\u001b[A\n",
      "Processed prompts:  46%|▍| 114/250 [00:27<00:03, 39.79it/s, est. speed input: 39\u001b[A\n",
      "Processed prompts:  48%|▍| 121/250 [00:27<00:02, 45.28it/s, est. speed input: 41\u001b[A\n",
      "Processed prompts:  51%|▌| 127/250 [00:28<00:03, 39.13it/s, est. speed input: 43\u001b[A\n",
      "Processed prompts:  53%|▌| 132/250 [00:28<00:03, 36.58it/s, est. speed input: 44\u001b[A\n",
      "Processed prompts:  57%|▌| 143/250 [00:28<00:02, 46.16it/s, est. speed input: 47\u001b[A\n",
      "Processed prompts:  59%|▌| 148/250 [00:28<00:02, 42.45it/s, est. speed input: 48\u001b[A\n",
      "Processed prompts:  62%|▌| 155/250 [00:28<00:02, 46.68it/s, est. speed input: 50\u001b[A\n",
      "Processed prompts:  64%|▋| 160/250 [00:28<00:02, 41.79it/s, est. speed input: 51\u001b[A\n",
      "Processed prompts:  66%|▋| 166/250 [00:28<00:01, 45.41it/s, est. speed input: 53\u001b[A\n",
      "Processed prompts:  70%|▋| 175/250 [00:29<00:01, 50.38it/s, est. speed input: 55\u001b[A\n",
      "Processed prompts:  72%|▋| 181/250 [00:29<00:01, 51.03it/s, est. speed input: 57\u001b[A\n",
      "Processed prompts:  75%|▊| 188/250 [00:29<00:01, 54.83it/s, est. speed input: 58\u001b[A\n",
      "Processed prompts:  78%|▊| 194/250 [00:29<00:01, 55.04it/s, est. speed input: 60\u001b[A\n",
      "Processed prompts:  81%|▊| 202/250 [00:29<00:00, 58.81it/s, est. speed input: 62\u001b[A\n",
      "Processed prompts:  85%|▊| 213/250 [00:29<00:00, 69.89it/s, est. speed input: 65\u001b[A\n",
      "Processed prompts:  88%|▉| 221/250 [00:29<00:00, 63.74it/s, est. speed input: 67\u001b[A\n",
      "Processed prompts:  91%|▉| 228/250 [00:29<00:00, 61.71it/s, est. speed input: 68\u001b[A\n",
      "Processed prompts:  94%|▉| 235/250 [00:30<00:00, 49.46it/s, est. speed input: 70\u001b[A\n",
      "Processed prompts:  96%|▉| 241/250 [00:30<00:00, 48.43it/s, est. speed input: 71\u001b[A\n",
      "Processed prompts:  99%|▉| 247/250 [00:30<00:00, 37.64it/s, est. speed input: 72\u001b[A\n",
      "Processed prompts: 100%|█| 250/250 [00:30<00:00,  8.15it/s, est. speed input: 72\u001b[A\n",
      "Running generate_until requests: 100%|████████| 250/250 [00:30<00:00,  8.15it/s]\n",
      "[2026-01-23 06:39:43] INFO evaluation_tracker.py:280: Output path not provided, skipping saving results aggregated\n",
      "vllm (pretrained=./Llama-3.2-3B-Instruct-W4A16-G128,add_bos_token=true), gen_kwargs: (None), limit: 250.0, num_fewshot: 5, batch_size: auto\n",
      "|Tasks|Version|     Filter     |n-shot|  Metric   |   |Value|   |Stderr|\n",
      "|-----|------:|----------------|-----:|-----------|---|----:|---|-----:|\n",
      "|gsm8k|      3|flexible-extract|     5|exact_match|↑  |0.664|±  |0.0299|\n",
      "|     |       |strict-match    |     5|exact_match|↑  |0.556|±  |0.0315|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# our Quantized model eval\n",
    "!lm_eval --model vllm \\\n",
    "  --model_args pretrained=\"./Llama-3.2-3B-Instruct-W4A16-G128\",add_bos_token=true \\\n",
    "  --tasks gsm8k \\\n",
    "  --num_fewshot 5 \\\n",
    "  --limit 250 \\\n",
    "  --batch_size 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f494b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original model eval\n",
    "!lm_eval --model vllm \\\n",
    "  --model_args pretrained=\"meta-llama/Llama-3.2-3B-Instruct\",add_bos_token=true,dtype=auto,max_model_len=4096 \\\n",
    "  --tasks gsm8k \\\n",
    "  --num_fewshot 5 \\\n",
    "  --limit 250 \\\n",
    "  --batch_size 'auto'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dada685f",
   "metadata": {},
   "source": [
    "**Quantized Model**\n",
    "\n",
    "|Tasks|Version|     Filter     |n-shot|  Metric   |   |Value|   |Stderr|\n",
    "|-----|------:|----------------|-----:|-----------|---|----:|---|-----:|\n",
    "|gsm8k|      3|flexible-extract|     5|exact_match|↑  | 0.64|±  |0.0304|\n",
    "|     |       |strict-match    |     5|exact_match|↑  | 0.54|±  |0.0316|\n",
    "\n",
    "**Original Model**\n",
    "\n",
    "|Tasks|Version|     Filter     |n-shot|  Metric   |   |Value|   |Stderr|\n",
    "|-----|------:|----------------|-----:|-----------|---|----:|---|-----:|\n",
    "|gsm8k|      3|flexible-extract|     5|exact_match|↑  |0.680|±  |0.0296|\n",
    "|     |       |strict-match    |     5|exact_match|↑  |0.608|±  |0.0309|\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca92d6f0",
   "metadata": {},
   "source": [
    "## 2.2. Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f7b8db",
   "metadata": {},
   "source": [
    "2:4 sparse pruning with/without FP8 quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9767f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from llmcompressor import oneshot\n",
    "from llmcompressor.modifiers.obcq import SparseGPTModifier\n",
    "from llmcompressor.modifiers.quantization import QuantizationModifier\n",
    "from llmcompressor.utils import dispatch_for_generation\n",
    "\n",
    "\n",
    "# Configuration\n",
    "MODEL_ID = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "DATASET_ID = \"HuggingFaceH4/ultrachat_200k\"\n",
    "DATASET_SPLIT = \"train_sft\"\n",
    "NUM_CALIBRATION_SAMPLES = 512\n",
    "MAX_SEQUENCE_LENGTH = 2048\n",
    "QUANT_ENABLE = False\n",
    "\n",
    "def preprocess(example):\n",
    "    \"\"\"Preprocess dataset examples.\"\"\"\n",
    "    return {\"text\": tokenizer.apply_chat_template(example[\"messages\"], tokenize=False)}\n",
    "\n",
    "\n",
    "def tokenize(sample):\n",
    "    \"\"\"Tokenize dataset examples.\"\"\"\n",
    "    return tokenizer(\n",
    "        sample[\"text\"],\n",
    "        padding=False,\n",
    "        max_length=MAX_SEQUENCE_LENGTH,\n",
    "        truncation=True,\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_recipe(fp8_enabled):\n",
    "    \"\"\"\n",
    "    Generate the compression recipe and save directory based on the FP8 flag.\n",
    "    \"\"\"\n",
    "    \n",
    "    base_recipe = [\n",
    "        SparseGPTModifier(\n",
    "            sparsity=0.5,\n",
    "            mask_structure=\"2:4\",\n",
    "            targets=[r\"re:model.layers.\\d*$\"],\n",
    "        )\n",
    "    ]\n",
    "    save_dir = MODEL_ID.rstrip(\"/\").split(\"/\")[-1] + \"2of4-sparse\"\n",
    "\n",
    "    if fp8_enabled:\n",
    "        base_recipe.append(\n",
    "            QuantizationModifier(\n",
    "                targets=[\"Linear\"],\n",
    "                ignore=[\"lm_head\"],\n",
    "                scheme=\"FP8_DYNAMIC\",\n",
    "            )\n",
    "        )\n",
    "        save_dir = (\n",
    "            MODEL_ID.rstrip(\"/\").split(\"/\")[-1] + \"2of4-W8A8-FP8-Dynamic-Per-Token\"\n",
    "        )\n",
    "\n",
    "        # check that asymmetric quantization is not being used\n",
    "        q_scheme = base_recipe[1].scheme\n",
    "        if not isinstance(q_scheme, str) and not q_scheme[\"weights\"].symmetric:\n",
    "            raise ValueError(\n",
    "                \"Asymmetric quantization with 2of4 sparsity is not supported by vLLM. \"\n",
    "                \"Please use symmetric quantization\"\n",
    "            )\n",
    "\n",
    "    return base_recipe, save_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef190f8",
   "metadata": {},
   "source": [
    "Prune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7321276b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a35e535dd542c49893cd57e4c0452b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1398/4116749871.py:40: DeprecationWarning: SparseGPTModifier has moved. In future, please initialize it from `llmcompressor.modifiers.pruning.sparsegpt.SparseGPTModifier`.\n",
      "  SparseGPTModifier(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:00:17.572250+0000 | reset | INFO - Compression lifecycle reset\n",
      "2026-01-27T04:00:17.573653+0000 | from_modifiers | INFO - Creating recipe from modifiers\n",
      "2026-01-27T04:00:17.579295+0000 | initialize | INFO - Compression lifecycle initialized for 1 modifiers\n",
      "2026-01-27T04:00:17.579625+0000 | IndependentPipeline | INFO - Inferred `SequentialPipeline` for `SparseGPTModifier`\n",
      "2026-01-27T04:00:17.723764+0000 | get_sequential_targets | WARNING - Passing sequential targets through modifiers is deprecated, please use `oneshot(sequential_targets=...)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing cache: 100%|██████████| 512/512 [00:00<00:00, 1346.75it/s]\n",
      "(1/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:00:28.903087+0000 | compress_modules | INFO - Sparsifying model.layers.0.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:00:29.572177+0000 | compress | METRIC - time 0.67s\n",
      "2026-01-27T04:00:29.572771+0000 | compress | METRIC - error 3512.94\n",
      "2026-01-27T04:00:29.573365+0000 | compress | METRIC - GPU 0 | usage: 12.23% | total memory: 25 GB\n",
      "2026-01-27T04:00:29.573604+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:00:29.573989+0000 | compress_modules | INFO - Sparsifying model.layers.0.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:00:30.110352+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:00:30.110715+0000 | compress | METRIC - error 1692.18\n",
      "2026-01-27T04:00:30.111038+0000 | compress | METRIC - GPU 0 | usage: 12.23% | total memory: 25 GB\n",
      "2026-01-27T04:00:30.111280+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:00:30.111895+0000 | compress_modules | INFO - Sparsifying model.layers.0.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:00:30.651810+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:00:30.652183+0000 | compress | METRIC - error 123.57\n",
      "2026-01-27T04:00:30.652673+0000 | compress | METRIC - GPU 0 | usage: 12.23% | total memory: 25 GB\n",
      "2026-01-27T04:00:30.653028+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:00:30.653428+0000 | compress_modules | INFO - Sparsifying model.layers.0.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:00:31.155505+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:00:31.155834+0000 | compress | METRIC - error 14.01\n",
      "2026-01-27T04:00:31.156257+0000 | compress | METRIC - GPU 0 | usage: 12.23% | total memory: 25 GB\n",
      "2026-01-27T04:00:31.156503+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:00:31.156928+0000 | compress_modules | INFO - Sparsifying model.layers.0.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:00:31.648015+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:00:31.648568+0000 | compress | METRIC - error 9359.94\n",
      "2026-01-27T04:00:31.649036+0000 | compress | METRIC - GPU 0 | usage: 12.23% | total memory: 25 GB\n",
      "2026-01-27T04:00:31.649268+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:00:31.649701+0000 | compress_modules | INFO - Sparsifying model.layers.0.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:00:32.137920+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:00:32.138474+0000 | compress | METRIC - error 8310.48\n",
      "2026-01-27T04:00:32.138911+0000 | compress | METRIC - GPU 0 | usage: 12.23% | total memory: 25 GB\n",
      "2026-01-27T04:00:32.139153+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:00:32.139577+0000 | compress_modules | INFO - Sparsifying model.layers.0.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:00:33.526937+0000 | compress | METRIC - time 1.39s\n",
      "2026-01-27T04:00:33.527867+0000 | compress | METRIC - error 89.05\n",
      "2026-01-27T04:00:33.528344+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:00:33.528588+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/29): Propagating: 100%|██████████| 512/512 [00:04<00:00, 113.87it/s]\n",
      "(2/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:00:49.164616+0000 | compress_modules | INFO - Sparsifying model.layers.1.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:00:49.675856+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:00:49.676498+0000 | compress | METRIC - error 5899.34\n",
      "2026-01-27T04:00:49.676936+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:00:49.677181+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:00:49.677593+0000 | compress_modules | INFO - Sparsifying model.layers.1.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:00:50.172178+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:00:50.172744+0000 | compress | METRIC - error 3315.65\n",
      "2026-01-27T04:00:50.173180+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:00:50.173419+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:00:50.173845+0000 | compress_modules | INFO - Sparsifying model.layers.1.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:00:50.749355+0000 | compress | METRIC - time 0.58s\n",
      "2026-01-27T04:00:50.750039+0000 | compress | METRIC - error 442.49\n",
      "2026-01-27T04:00:50.750582+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:00:50.750925+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:00:50.751277+0000 | compress_modules | INFO - Sparsifying model.layers.1.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:00:51.332166+0000 | compress | METRIC - time 0.58s\n",
      "2026-01-27T04:00:51.332876+0000 | compress | METRIC - error 37.64\n",
      "2026-01-27T04:00:51.333342+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:00:51.333678+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:00:51.334056+0000 | compress_modules | INFO - Sparsifying model.layers.1.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:00:51.865970+0000 | compress | METRIC - time 0.53s\n",
      "2026-01-27T04:00:51.866562+0000 | compress | METRIC - error 12024.48\n",
      "2026-01-27T04:00:51.867015+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:00:51.867237+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:00:51.867619+0000 | compress_modules | INFO - Sparsifying model.layers.1.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:00:52.358292+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:00:52.358636+0000 | compress | METRIC - error 10420.45\n",
      "2026-01-27T04:00:52.359057+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:00:52.359295+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:00:52.359706+0000 | compress_modules | INFO - Sparsifying model.layers.1.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:00:53.739541+0000 | compress | METRIC - time 1.38s\n",
      "2026-01-27T04:00:53.740005+0000 | compress | METRIC - error 678.84\n",
      "2026-01-27T04:00:53.740507+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:00:53.740801+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(2/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 170.66it/s]\n",
      "(3/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 48.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:01:07.493460+0000 | compress_modules | INFO - Sparsifying model.layers.2.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:01:07.986198+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:01:07.986667+0000 | compress | METRIC - error 30274.27\n",
      "2026-01-27T04:01:07.987023+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:01:07.987252+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:01:07.987676+0000 | compress_modules | INFO - Sparsifying model.layers.2.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:01:08.474073+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:01:08.474474+0000 | compress | METRIC - error 17284.99\n",
      "2026-01-27T04:01:08.474907+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:01:08.475137+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:01:08.475624+0000 | compress_modules | INFO - Sparsifying model.layers.2.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:01:08.960307+0000 | compress | METRIC - time 0.48s\n",
      "2026-01-27T04:01:08.960670+0000 | compress | METRIC - error 2196.99\n",
      "2026-01-27T04:01:08.961136+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:01:08.961387+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:01:08.961814+0000 | compress_modules | INFO - Sparsifying model.layers.2.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:01:09.444615+0000 | compress | METRIC - time 0.48s\n",
      "2026-01-27T04:01:09.445051+0000 | compress | METRIC - error 47.97\n",
      "2026-01-27T04:01:09.445474+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:01:09.445728+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:01:09.446157+0000 | compress_modules | INFO - Sparsifying model.layers.2.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:01:09.935760+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:01:09.936107+0000 | compress | METRIC - error 19059.47\n",
      "2026-01-27T04:01:09.936546+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:01:09.936769+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:01:09.937148+0000 | compress_modules | INFO - Sparsifying model.layers.2.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:01:10.425994+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:01:10.426438+0000 | compress | METRIC - error 15952.97\n",
      "2026-01-27T04:01:10.426855+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:01:10.427066+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:01:10.427512+0000 | compress_modules | INFO - Sparsifying model.layers.2.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:01:11.802514+0000 | compress | METRIC - time 1.37s\n",
      "2026-01-27T04:01:11.803327+0000 | compress | METRIC - error 235.67\n",
      "2026-01-27T04:01:11.803756+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:01:11.803979+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.64it/s]\n",
      "(4/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:01:25.566107+0000 | compress_modules | INFO - Sparsifying model.layers.3.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:01:26.060011+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:01:26.060379+0000 | compress | METRIC - error 37609.98\n",
      "2026-01-27T04:01:26.060768+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:01:26.060984+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:01:26.061342+0000 | compress_modules | INFO - Sparsifying model.layers.3.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:01:26.572171+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:01:26.572680+0000 | compress | METRIC - error 21017.32\n",
      "2026-01-27T04:01:26.573147+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:01:26.573415+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:01:26.573890+0000 | compress_modules | INFO - Sparsifying model.layers.3.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:01:27.110902+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:01:27.111210+0000 | compress | METRIC - error 3669.19\n",
      "2026-01-27T04:01:27.111734+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:01:27.112009+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:01:27.112386+0000 | compress_modules | INFO - Sparsifying model.layers.3.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:01:27.652089+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:01:27.652498+0000 | compress | METRIC - error 112.93\n",
      "2026-01-27T04:01:27.652913+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:01:27.653191+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:01:27.653508+0000 | compress_modules | INFO - Sparsifying model.layers.3.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:01:28.170856+0000 | compress | METRIC - time 0.52s\n",
      "2026-01-27T04:01:28.171212+0000 | compress | METRIC - error 29187.85\n",
      "2026-01-27T04:01:28.171709+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:01:28.171940+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:01:28.172333+0000 | compress_modules | INFO - Sparsifying model.layers.3.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:01:28.680674+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:01:28.681119+0000 | compress | METRIC - error 21823.59\n",
      "2026-01-27T04:01:28.681562+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:01:28.681801+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:01:28.682218+0000 | compress_modules | INFO - Sparsifying model.layers.3.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:01:30.100578+0000 | compress | METRIC - time 1.42s\n",
      "2026-01-27T04:01:30.101544+0000 | compress | METRIC - error 427.25\n",
      "2026-01-27T04:01:30.102147+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:01:30.102437+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(4/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 170.27it/s]\n",
      "(5/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:01:43.904014+0000 | compress_modules | INFO - Sparsifying model.layers.4.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:01:44.450641+0000 | compress | METRIC - time 0.55s\n",
      "2026-01-27T04:01:44.451139+0000 | compress | METRIC - error 30747.26\n",
      "2026-01-27T04:01:44.451573+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:01:44.451791+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:01:44.452155+0000 | compress_modules | INFO - Sparsifying model.layers.4.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:01:44.990133+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:01:44.990600+0000 | compress | METRIC - error 15987.66\n",
      "2026-01-27T04:01:44.991066+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:01:44.991284+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:01:44.991676+0000 | compress_modules | INFO - Sparsifying model.layers.4.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:01:45.528454+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:01:45.528824+0000 | compress | METRIC - error 3233.94\n",
      "2026-01-27T04:01:45.529292+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:01:45.529559+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:01:45.530022+0000 | compress_modules | INFO - Sparsifying model.layers.4.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:01:46.038986+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:01:46.039387+0000 | compress | METRIC - error 169.09\n",
      "2026-01-27T04:01:46.039754+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:01:46.039958+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:01:46.040293+0000 | compress_modules | INFO - Sparsifying model.layers.4.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:01:46.582891+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:01:46.583287+0000 | compress | METRIC - error 38335.11\n",
      "2026-01-27T04:01:46.583705+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:01:46.583932+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:01:46.584282+0000 | compress_modules | INFO - Sparsifying model.layers.4.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:01:47.136704+0000 | compress | METRIC - time 0.55s\n",
      "2026-01-27T04:01:47.137140+0000 | compress | METRIC - error 24768.79\n",
      "2026-01-27T04:01:47.137567+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:01:47.137802+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:01:47.138223+0000 | compress_modules | INFO - Sparsifying model.layers.4.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:01:48.618846+0000 | compress | METRIC - time 1.48s\n",
      "2026-01-27T04:01:48.619567+0000 | compress | METRIC - error 633.43\n",
      "2026-01-27T04:01:48.619970+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:01:48.620187+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(5/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 170.90it/s]\n",
      "(6/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:02:02.417053+0000 | compress_modules | INFO - Sparsifying model.layers.5.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:02:02.911680+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:02:02.912086+0000 | compress | METRIC - error 40808.35\n",
      "2026-01-27T04:02:02.912411+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:02.912681+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:02:02.913199+0000 | compress_modules | INFO - Sparsifying model.layers.5.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:02:03.399085+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:02:03.399523+0000 | compress | METRIC - error 22779.85\n",
      "2026-01-27T04:02:03.399936+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:03.400158+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:02:03.400570+0000 | compress_modules | INFO - Sparsifying model.layers.5.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:02:03.886840+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:02:03.887323+0000 | compress | METRIC - error 3061.05\n",
      "2026-01-27T04:02:03.887782+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:03.888042+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:02:03.888583+0000 | compress_modules | INFO - Sparsifying model.layers.5.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:02:04.397979+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:02:04.398414+0000 | compress | METRIC - error 257.85\n",
      "2026-01-27T04:02:04.399052+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:04.399281+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:02:04.399845+0000 | compress_modules | INFO - Sparsifying model.layers.5.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:02:04.896671+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:02:04.897034+0000 | compress | METRIC - error 42016.09\n",
      "2026-01-27T04:02:04.897454+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:04.897682+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:02:04.898092+0000 | compress_modules | INFO - Sparsifying model.layers.5.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:02:05.426839+0000 | compress | METRIC - time 0.53s\n",
      "2026-01-27T04:02:05.427358+0000 | compress | METRIC - error 28912.22\n",
      "2026-01-27T04:02:05.427779+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:05.428080+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:02:05.428361+0000 | compress_modules | INFO - Sparsifying model.layers.5.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:02:06.892117+0000 | compress | METRIC - time 1.46s\n",
      "2026-01-27T04:02:06.892934+0000 | compress | METRIC - error 897.21\n",
      "2026-01-27T04:02:06.893371+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:02:06.893615+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(6/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 171.07it/s]\n",
      "(7/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:02:20.680716+0000 | compress_modules | INFO - Sparsifying model.layers.6.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:02:21.220180+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:02:21.220613+0000 | compress | METRIC - error 44018.45\n",
      "2026-01-27T04:02:21.221111+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:21.221501+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:02:21.221869+0000 | compress_modules | INFO - Sparsifying model.layers.6.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:02:21.776882+0000 | compress | METRIC - time 0.55s\n",
      "2026-01-27T04:02:21.777427+0000 | compress | METRIC - error 23294.31\n",
      "2026-01-27T04:02:21.777889+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:21.778128+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:02:21.778575+0000 | compress_modules | INFO - Sparsifying model.layers.6.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:02:22.321213+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:02:22.321563+0000 | compress | METRIC - error 3586.75\n",
      "2026-01-27T04:02:22.321936+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:22.322154+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:02:22.322530+0000 | compress_modules | INFO - Sparsifying model.layers.6.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:02:22.827888+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:02:22.828256+0000 | compress | METRIC - error 375.74\n",
      "2026-01-27T04:02:22.828636+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:22.828878+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:02:22.829221+0000 | compress_modules | INFO - Sparsifying model.layers.6.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:02:23.324915+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:02:23.325263+0000 | compress | METRIC - error 44520.00\n",
      "2026-01-27T04:02:23.325681+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:23.325918+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:02:23.326191+0000 | compress_modules | INFO - Sparsifying model.layers.6.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:02:23.821035+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:02:23.821447+0000 | compress | METRIC - error 31386.95\n",
      "2026-01-27T04:02:23.821878+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:23.822116+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:02:23.822535+0000 | compress_modules | INFO - Sparsifying model.layers.6.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:02:25.257344+0000 | compress | METRIC - time 1.43s\n",
      "2026-01-27T04:02:25.258096+0000 | compress | METRIC - error 1079.86\n",
      "2026-01-27T04:02:25.258737+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:02:25.258977+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(7/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.80it/s]\n",
      "(8/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:02:39.075922+0000 | compress_modules | INFO - Sparsifying model.layers.7.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:02:39.589931+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:02:39.590298+0000 | compress | METRIC - error 43111.91\n",
      "2026-01-27T04:02:39.590762+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:39.590997+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:02:39.591277+0000 | compress_modules | INFO - Sparsifying model.layers.7.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:02:40.099229+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:02:40.099690+0000 | compress | METRIC - error 26032.93\n",
      "2026-01-27T04:02:40.100108+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:40.100419+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:02:40.100823+0000 | compress_modules | INFO - Sparsifying model.layers.7.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:02:40.636356+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:02:40.636745+0000 | compress | METRIC - error 3520.44\n",
      "2026-01-27T04:02:40.637350+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:40.637597+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:02:40.637987+0000 | compress_modules | INFO - Sparsifying model.layers.7.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:02:41.173142+0000 | compress | METRIC - time 0.53s\n",
      "2026-01-27T04:02:41.173551+0000 | compress | METRIC - error 477.92\n",
      "2026-01-27T04:02:41.174200+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:41.174486+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:02:41.175091+0000 | compress_modules | INFO - Sparsifying model.layers.7.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:02:41.718918+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:02:41.719284+0000 | compress | METRIC - error 43519.87\n",
      "2026-01-27T04:02:41.719753+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:41.720009+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:02:41.720480+0000 | compress_modules | INFO - Sparsifying model.layers.7.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:02:42.266937+0000 | compress | METRIC - time 0.55s\n",
      "2026-01-27T04:02:42.267365+0000 | compress | METRIC - error 33079.56\n",
      "2026-01-27T04:02:42.267838+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:42.268104+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:02:42.268419+0000 | compress_modules | INFO - Sparsifying model.layers.7.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:02:43.696523+0000 | compress | METRIC - time 1.43s\n",
      "2026-01-27T04:02:43.697323+0000 | compress | METRIC - error 1204.99\n",
      "2026-01-27T04:02:43.697742+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:02:43.697975+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(8/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 170.36it/s]\n",
      "(9/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:02:57.528390+0000 | compress_modules | INFO - Sparsifying model.layers.8.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:02:58.041921+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:02:58.042377+0000 | compress | METRIC - error 49637.70\n",
      "2026-01-27T04:02:58.042819+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:58.043041+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:02:58.043419+0000 | compress_modules | INFO - Sparsifying model.layers.8.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:02:58.547842+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:02:58.548232+0000 | compress | METRIC - error 28493.73\n",
      "2026-01-27T04:02:58.548706+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:58.548951+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:02:58.549222+0000 | compress_modules | INFO - Sparsifying model.layers.8.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:02:59.053420+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:02:59.053759+0000 | compress | METRIC - error 4154.93\n",
      "2026-01-27T04:02:59.054180+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:59.054429+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:02:59.054836+0000 | compress_modules | INFO - Sparsifying model.layers.8.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:02:59.560550+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:02:59.560879+0000 | compress | METRIC - error 656.57\n",
      "2026-01-27T04:02:59.561286+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:02:59.561527+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:02:59.561948+0000 | compress_modules | INFO - Sparsifying model.layers.8.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:03:00.074548+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:03:00.074987+0000 | compress | METRIC - error 46160.95\n",
      "2026-01-27T04:03:00.075411+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:00.075642+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:03:00.076065+0000 | compress_modules | INFO - Sparsifying model.layers.8.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:03:00.589019+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:03:00.589351+0000 | compress | METRIC - error 34689.62\n",
      "2026-01-27T04:03:00.589766+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:00.590004+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:03:00.590461+0000 | compress_modules | INFO - Sparsifying model.layers.8.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:03:02.009875+0000 | compress | METRIC - time 1.42s\n",
      "2026-01-27T04:03:02.010828+0000 | compress | METRIC - error 1239.90\n",
      "2026-01-27T04:03:02.011326+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:03:02.011575+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(9/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.82it/s]\n",
      "(10/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:03:15.834773+0000 | compress_modules | INFO - Sparsifying model.layers.9.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:03:16.349849+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:03:16.350236+0000 | compress | METRIC - error 52219.43\n",
      "2026-01-27T04:03:16.350738+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:16.350984+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:03:16.351263+0000 | compress_modules | INFO - Sparsifying model.layers.9.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:03:16.840469+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:03:16.840836+0000 | compress | METRIC - error 30416.41\n",
      "2026-01-27T04:03:16.841268+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:16.841539+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:03:16.841952+0000 | compress_modules | INFO - Sparsifying model.layers.9.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:03:17.343810+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:03:17.344148+0000 | compress | METRIC - error 5290.73\n",
      "2026-01-27T04:03:17.344483+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:17.344706+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:03:17.345226+0000 | compress_modules | INFO - Sparsifying model.layers.9.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:03:17.840662+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:03:17.840993+0000 | compress | METRIC - error 738.83\n",
      "2026-01-27T04:03:17.841429+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:17.841747+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:03:17.842013+0000 | compress_modules | INFO - Sparsifying model.layers.9.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:03:18.338514+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:03:18.338853+0000 | compress | METRIC - error 44339.84\n",
      "2026-01-27T04:03:18.339265+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:18.339527+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:03:18.339930+0000 | compress_modules | INFO - Sparsifying model.layers.9.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:03:18.853687+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:03:18.854045+0000 | compress | METRIC - error 35058.26\n",
      "2026-01-27T04:03:18.854478+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:18.854777+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:03:18.855100+0000 | compress_modules | INFO - Sparsifying model.layers.9.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:03:20.369911+0000 | compress | METRIC - time 1.51s\n",
      "2026-01-27T04:03:20.370909+0000 | compress | METRIC - error 1271.13\n",
      "2026-01-27T04:03:20.371381+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:03:20.371616+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(10/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.66it/s]\n",
      "(11/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:03:34.212580+0000 | compress_modules | INFO - Sparsifying model.layers.10.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:03:34.727136+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:03:34.727627+0000 | compress | METRIC - error 51454.09\n",
      "2026-01-27T04:03:34.728085+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:34.728338+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:03:34.728759+0000 | compress_modules | INFO - Sparsifying model.layers.10.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:03:35.240207+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:03:35.240747+0000 | compress | METRIC - error 29932.41\n",
      "2026-01-27T04:03:35.241208+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:35.241462+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:03:35.241892+0000 | compress_modules | INFO - Sparsifying model.layers.10.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:03:35.747297+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:03:35.747640+0000 | compress | METRIC - error 4163.23\n",
      "2026-01-27T04:03:35.748052+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:35.748290+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:03:35.748706+0000 | compress_modules | INFO - Sparsifying model.layers.10.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:03:36.239949+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:03:36.240410+0000 | compress | METRIC - error 628.01\n",
      "2026-01-27T04:03:36.240728+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:36.240940+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:03:36.241317+0000 | compress_modules | INFO - Sparsifying model.layers.10.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:03:36.738436+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:03:36.738845+0000 | compress | METRIC - error 42897.80\n",
      "2026-01-27T04:03:36.739243+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:36.739702+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:03:36.740050+0000 | compress_modules | INFO - Sparsifying model.layers.10.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:03:37.249167+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:03:37.249539+0000 | compress | METRIC - error 36247.85\n",
      "2026-01-27T04:03:37.249955+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:37.250193+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:03:37.250474+0000 | compress_modules | INFO - Sparsifying model.layers.10.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:03:38.660791+0000 | compress | METRIC - time 1.41s\n",
      "2026-01-27T04:03:38.661612+0000 | compress | METRIC - error 1321.10\n",
      "2026-01-27T04:03:38.662033+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:03:38.662348+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(11/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 170.03it/s]\n",
      "(12/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:03:52.513180+0000 | compress_modules | INFO - Sparsifying model.layers.11.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:03:53.028911+0000 | compress | METRIC - time 0.52s\n",
      "2026-01-27T04:03:53.029347+0000 | compress | METRIC - error 45086.07\n",
      "2026-01-27T04:03:53.029796+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:53.030033+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:03:53.030329+0000 | compress_modules | INFO - Sparsifying model.layers.11.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:03:53.536965+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:03:53.537295+0000 | compress | METRIC - error 25683.25\n",
      "2026-01-27T04:03:53.537714+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:53.537950+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:03:53.538364+0000 | compress_modules | INFO - Sparsifying model.layers.11.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:03:54.045071+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:03:54.045494+0000 | compress | METRIC - error 5076.11\n",
      "2026-01-27T04:03:54.045918+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:54.046159+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:03:54.046464+0000 | compress_modules | INFO - Sparsifying model.layers.11.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:03:54.541486+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:03:54.542012+0000 | compress | METRIC - error 867.05\n",
      "2026-01-27T04:03:54.542521+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:54.542771+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:03:54.543136+0000 | compress_modules | INFO - Sparsifying model.layers.11.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:03:55.058293+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:03:55.058710+0000 | compress | METRIC - error 42475.04\n",
      "2026-01-27T04:03:55.059148+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:55.059407+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:03:55.059833+0000 | compress_modules | INFO - Sparsifying model.layers.11.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:03:55.575118+0000 | compress | METRIC - time 0.52s\n",
      "2026-01-27T04:03:55.575480+0000 | compress | METRIC - error 38010.22\n",
      "2026-01-27T04:03:55.575907+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:03:55.576149+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:03:55.576580+0000 | compress_modules | INFO - Sparsifying model.layers.11.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:03:57.014583+0000 | compress | METRIC - time 1.44s\n",
      "2026-01-27T04:03:57.015408+0000 | compress | METRIC - error 1485.48\n",
      "2026-01-27T04:03:57.015839+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:03:57.016082+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(12/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.99it/s]\n",
      "(13/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:04:10.880403+0000 | compress_modules | INFO - Sparsifying model.layers.12.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:04:11.424744+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:04:11.425263+0000 | compress | METRIC - error 60684.00\n",
      "2026-01-27T04:04:11.425832+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:04:11.426095+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:04:11.426492+0000 | compress_modules | INFO - Sparsifying model.layers.12.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:04:11.960669+0000 | compress | METRIC - time 0.53s\n",
      "2026-01-27T04:04:11.961061+0000 | compress | METRIC - error 34769.42\n",
      "2026-01-27T04:04:11.961498+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:04:11.961708+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:04:11.962188+0000 | compress_modules | INFO - Sparsifying model.layers.12.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:04:12.499686+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:04:12.500087+0000 | compress | METRIC - error 5423.07\n",
      "2026-01-27T04:04:12.500580+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:04:12.500904+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:04:12.501219+0000 | compress_modules | INFO - Sparsifying model.layers.12.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:04:13.039042+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:04:13.039547+0000 | compress | METRIC - error 1152.60\n",
      "2026-01-27T04:04:13.039865+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:04:13.040107+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:04:13.040578+0000 | compress_modules | INFO - Sparsifying model.layers.12.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:04:13.596067+0000 | compress | METRIC - time 0.56s\n",
      "2026-01-27T04:04:13.596586+0000 | compress | METRIC - error 44786.74\n",
      "2026-01-27T04:04:13.597078+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:04:13.597309+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:04:13.597606+0000 | compress_modules | INFO - Sparsifying model.layers.12.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:04:14.119384+0000 | compress | METRIC - time 0.52s\n",
      "2026-01-27T04:04:14.119730+0000 | compress | METRIC - error 41217.59\n",
      "2026-01-27T04:04:14.120128+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:04:14.120363+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:04:14.120760+0000 | compress_modules | INFO - Sparsifying model.layers.12.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:04:15.517499+0000 | compress | METRIC - time 1.40s\n",
      "2026-01-27T04:04:15.518374+0000 | compress | METRIC - error 1760.56\n",
      "2026-01-27T04:04:15.518830+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:04:15.519069+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(13/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 170.49it/s]\n",
      "(14/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:04:29.381075+0000 | compress_modules | INFO - Sparsifying model.layers.13.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:04:29.904150+0000 | compress | METRIC - time 0.52s\n",
      "2026-01-27T04:04:29.904906+0000 | compress | METRIC - error 54342.52\n",
      "2026-01-27T04:04:29.905419+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:04:29.905672+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:04:29.906065+0000 | compress_modules | INFO - Sparsifying model.layers.13.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:04:30.427592+0000 | compress | METRIC - time 0.52s\n",
      "2026-01-27T04:04:30.428348+0000 | compress | METRIC - error 32673.86\n",
      "2026-01-27T04:04:30.428899+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:04:30.429215+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:04:30.429735+0000 | compress_modules | INFO - Sparsifying model.layers.13.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:04:30.952747+0000 | compress | METRIC - time 0.52s\n",
      "2026-01-27T04:04:30.953429+0000 | compress | METRIC - error 5491.58\n",
      "2026-01-27T04:04:30.953855+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:04:30.954088+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:04:30.954495+0000 | compress_modules | INFO - Sparsifying model.layers.13.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:04:31.475417+0000 | compress | METRIC - time 0.52s\n",
      "2026-01-27T04:04:31.476085+0000 | compress | METRIC - error 1243.75\n",
      "2026-01-27T04:04:31.476523+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:04:31.476750+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:04:31.477161+0000 | compress_modules | INFO - Sparsifying model.layers.13.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:04:32.000395+0000 | compress | METRIC - time 0.52s\n",
      "2026-01-27T04:04:32.001001+0000 | compress | METRIC - error 49858.95\n",
      "2026-01-27T04:04:32.001458+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:04:32.001721+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:04:32.002135+0000 | compress_modules | INFO - Sparsifying model.layers.13.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:04:32.516549+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:04:32.516940+0000 | compress | METRIC - error 45151.93\n",
      "2026-01-27T04:04:32.517347+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:04:32.517723+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:04:32.518074+0000 | compress_modules | INFO - Sparsifying model.layers.13.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:04:33.918630+0000 | compress | METRIC - time 1.40s\n",
      "2026-01-27T04:04:33.919521+0000 | compress | METRIC - error 2111.62\n",
      "2026-01-27T04:04:33.919973+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:04:33.920204+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(14/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.82it/s]\n",
      "(15/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:04:47.784065+0000 | compress_modules | INFO - Sparsifying model.layers.14.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:04:48.337228+0000 | compress | METRIC - time 0.55s\n",
      "2026-01-27T04:04:48.337738+0000 | compress | METRIC - error 65009.01\n",
      "2026-01-27T04:04:48.338269+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:04:48.338533+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:04:48.338926+0000 | compress_modules | INFO - Sparsifying model.layers.14.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:04:48.886000+0000 | compress | METRIC - time 0.55s\n",
      "2026-01-27T04:04:48.886403+0000 | compress | METRIC - error 30759.89\n",
      "2026-01-27T04:04:48.886847+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:04:48.887187+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:04:48.887557+0000 | compress_modules | INFO - Sparsifying model.layers.14.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:04:49.414062+0000 | compress | METRIC - time 0.53s\n",
      "2026-01-27T04:04:49.414438+0000 | compress | METRIC - error 5993.67\n",
      "2026-01-27T04:04:49.414828+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:04:49.415051+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:04:49.415341+0000 | compress_modules | INFO - Sparsifying model.layers.14.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:04:49.920186+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:04:49.920622+0000 | compress | METRIC - error 1646.92\n",
      "2026-01-27T04:04:49.920940+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:04:49.921157+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:04:49.921560+0000 | compress_modules | INFO - Sparsifying model.layers.14.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:04:50.420198+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:04:50.420619+0000 | compress | METRIC - error 55983.21\n",
      "2026-01-27T04:04:50.421022+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:04:50.421236+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:04:50.421622+0000 | compress_modules | INFO - Sparsifying model.layers.14.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:04:50.919696+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:04:50.920048+0000 | compress | METRIC - error 49533.77\n",
      "2026-01-27T04:04:50.920494+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:04:50.920747+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:04:50.921134+0000 | compress_modules | INFO - Sparsifying model.layers.14.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:04:52.313882+0000 | compress | METRIC - time 1.39s\n",
      "2026-01-27T04:04:52.314714+0000 | compress | METRIC - error 2668.27\n",
      "2026-01-27T04:04:52.315175+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:04:52.315432+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(15/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.60it/s]\n",
      "(16/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:05:06.172221+0000 | compress_modules | INFO - Sparsifying model.layers.15.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:05:06.666591+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:05:06.667014+0000 | compress | METRIC - error 63613.13\n",
      "2026-01-27T04:05:06.667477+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:05:06.667746+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:05:06.668145+0000 | compress_modules | INFO - Sparsifying model.layers.15.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:05:07.186142+0000 | compress | METRIC - time 0.52s\n",
      "2026-01-27T04:05:07.186521+0000 | compress | METRIC - error 31283.46\n",
      "2026-01-27T04:05:07.186828+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:05:07.187065+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:05:07.187570+0000 | compress_modules | INFO - Sparsifying model.layers.15.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:05:07.724469+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:05:07.724861+0000 | compress | METRIC - error 6584.72\n",
      "2026-01-27T04:05:07.725290+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:05:07.725632+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:05:07.726096+0000 | compress_modules | INFO - Sparsifying model.layers.15.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:05:08.263468+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:05:08.263851+0000 | compress | METRIC - error 1024.59\n",
      "2026-01-27T04:05:08.264271+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:05:08.264531+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:05:08.264972+0000 | compress_modules | INFO - Sparsifying model.layers.15.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:05:08.809626+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:05:08.810065+0000 | compress | METRIC - error 62792.41\n",
      "2026-01-27T04:05:08.810524+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:05:08.810792+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:05:08.811181+0000 | compress_modules | INFO - Sparsifying model.layers.15.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:05:09.355666+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:05:09.356223+0000 | compress | METRIC - error 49987.13\n",
      "2026-01-27T04:05:09.356688+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:05:09.356996+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:05:09.357305+0000 | compress_modules | INFO - Sparsifying model.layers.15.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:05:10.803913+0000 | compress | METRIC - time 1.45s\n",
      "2026-01-27T04:05:10.804793+0000 | compress | METRIC - error 2767.85\n",
      "2026-01-27T04:05:10.805201+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:05:10.805457+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(16/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 170.10it/s]\n",
      "(17/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:05:24.667267+0000 | compress_modules | INFO - Sparsifying model.layers.16.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:05:25.220747+0000 | compress | METRIC - time 0.55s\n",
      "2026-01-27T04:05:25.221398+0000 | compress | METRIC - error 62290.31\n",
      "2026-01-27T04:05:25.221887+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:05:25.222111+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:05:25.222481+0000 | compress_modules | INFO - Sparsifying model.layers.16.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:05:25.758263+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:05:25.758731+0000 | compress | METRIC - error 32272.24\n",
      "2026-01-27T04:05:25.759128+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:05:25.759386+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:05:25.759839+0000 | compress_modules | INFO - Sparsifying model.layers.16.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:05:26.295267+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:05:26.295671+0000 | compress | METRIC - error 5750.99\n",
      "2026-01-27T04:05:26.296087+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:05:26.296297+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:05:26.296653+0000 | compress_modules | INFO - Sparsifying model.layers.16.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:05:26.833710+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:05:26.834376+0000 | compress | METRIC - error 677.56\n",
      "2026-01-27T04:05:26.834817+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:05:26.835122+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:05:26.835469+0000 | compress_modules | INFO - Sparsifying model.layers.16.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:05:27.335578+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:05:27.335957+0000 | compress | METRIC - error 66538.64\n",
      "2026-01-27T04:05:27.336273+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:05:27.336525+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:05:27.337018+0000 | compress_modules | INFO - Sparsifying model.layers.16.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:05:27.832073+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:05:27.832440+0000 | compress | METRIC - error 50687.65\n",
      "2026-01-27T04:05:27.832817+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:05:27.833020+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:05:27.833362+0000 | compress_modules | INFO - Sparsifying model.layers.16.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:05:29.217072+0000 | compress | METRIC - time 1.38s\n",
      "2026-01-27T04:05:29.217978+0000 | compress | METRIC - error 2633.93\n",
      "2026-01-27T04:05:29.218441+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:05:29.218701+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(17/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 170.02it/s]\n",
      "(18/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:05:43.090836+0000 | compress_modules | INFO - Sparsifying model.layers.17.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:05:43.586716+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:05:43.587117+0000 | compress | METRIC - error 60278.14\n",
      "2026-01-27T04:05:43.587561+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:05:43.587877+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:05:43.588495+0000 | compress_modules | INFO - Sparsifying model.layers.17.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:05:44.075875+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:05:44.076274+0000 | compress | METRIC - error 29299.81\n",
      "2026-01-27T04:05:44.076694+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:05:44.076913+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:05:44.077284+0000 | compress_modules | INFO - Sparsifying model.layers.17.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:05:44.568252+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:05:44.568622+0000 | compress | METRIC - error 6090.84\n",
      "2026-01-27T04:05:44.569048+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:05:44.569290+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:05:44.569704+0000 | compress_modules | INFO - Sparsifying model.layers.17.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:05:45.057783+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:05:45.058200+0000 | compress | METRIC - error 643.37\n",
      "2026-01-27T04:05:45.058702+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:05:45.059064+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:05:45.059423+0000 | compress_modules | INFO - Sparsifying model.layers.17.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:05:45.557289+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:05:45.557743+0000 | compress | METRIC - error 69049.05\n",
      "2026-01-27T04:05:45.558159+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:05:45.558487+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:05:45.558834+0000 | compress_modules | INFO - Sparsifying model.layers.17.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:05:46.056165+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:05:46.056543+0000 | compress | METRIC - error 51888.20\n",
      "2026-01-27T04:05:46.056941+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:05:46.057164+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:05:46.057597+0000 | compress_modules | INFO - Sparsifying model.layers.17.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:05:47.453984+0000 | compress | METRIC - time 1.40s\n",
      "2026-01-27T04:05:47.454888+0000 | compress | METRIC - error 2700.29\n",
      "2026-01-27T04:05:47.455459+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:05:47.455779+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(18/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.95it/s]\n",
      "(19/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:06:01.327718+0000 | compress_modules | INFO - Sparsifying model.layers.18.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:06:01.873257+0000 | compress | METRIC - time 0.55s\n",
      "2026-01-27T04:06:01.873727+0000 | compress | METRIC - error 60676.88\n",
      "2026-01-27T04:06:01.874160+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:01.874387+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:06:01.874754+0000 | compress_modules | INFO - Sparsifying model.layers.18.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:06:02.411812+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:06:02.412337+0000 | compress | METRIC - error 28633.96\n",
      "2026-01-27T04:06:02.412789+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:02.413087+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:06:02.413410+0000 | compress_modules | INFO - Sparsifying model.layers.18.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:06:02.949561+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:06:02.949973+0000 | compress | METRIC - error 6838.00\n",
      "2026-01-27T04:06:02.950468+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:02.950780+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:06:02.951239+0000 | compress_modules | INFO - Sparsifying model.layers.18.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:06:03.486904+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:06:03.487378+0000 | compress | METRIC - error 722.66\n",
      "2026-01-27T04:06:03.487891+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:03.488149+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:06:03.488530+0000 | compress_modules | INFO - Sparsifying model.layers.18.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:06:04.027677+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:06:04.028230+0000 | compress | METRIC - error 72551.24\n",
      "2026-01-27T04:06:04.028685+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:04.028939+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:06:04.029417+0000 | compress_modules | INFO - Sparsifying model.layers.18.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:06:04.571390+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:06:04.571731+0000 | compress | METRIC - error 55340.01\n",
      "2026-01-27T04:06:04.572273+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:04.572524+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:06:04.572951+0000 | compress_modules | INFO - Sparsifying model.layers.18.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:06:05.963185+0000 | compress | METRIC - time 1.39s\n",
      "2026-01-27T04:06:05.964104+0000 | compress | METRIC - error 2902.66\n",
      "2026-01-27T04:06:05.964615+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:06:05.964862+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(19/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.33it/s]\n",
      "(20/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:06:19.850987+0000 | compress_modules | INFO - Sparsifying model.layers.19.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:06:20.347538+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:06:20.347939+0000 | compress | METRIC - error 56454.79\n",
      "2026-01-27T04:06:20.348374+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:20.348639+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:06:20.349006+0000 | compress_modules | INFO - Sparsifying model.layers.19.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:06:20.835420+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:06:20.835794+0000 | compress | METRIC - error 28059.09\n",
      "2026-01-27T04:06:20.836173+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:20.836412+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:06:20.836846+0000 | compress_modules | INFO - Sparsifying model.layers.19.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:06:21.321341+0000 | compress | METRIC - time 0.48s\n",
      "2026-01-27T04:06:21.321704+0000 | compress | METRIC - error 6909.87\n",
      "2026-01-27T04:06:21.322085+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:21.322415+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:06:21.322750+0000 | compress_modules | INFO - Sparsifying model.layers.19.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:06:21.861216+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:06:21.861728+0000 | compress | METRIC - error 1020.29\n",
      "2026-01-27T04:06:21.862157+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:21.862456+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:06:21.862938+0000 | compress_modules | INFO - Sparsifying model.layers.19.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:06:22.408865+0000 | compress | METRIC - time 0.55s\n",
      "2026-01-27T04:06:22.409472+0000 | compress | METRIC - error 74695.16\n",
      "2026-01-27T04:06:22.409946+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:22.410211+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:06:22.410628+0000 | compress_modules | INFO - Sparsifying model.layers.19.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:06:22.950156+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:06:22.950565+0000 | compress | METRIC - error 58573.75\n",
      "2026-01-27T04:06:22.950998+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:22.951244+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:06:22.951709+0000 | compress_modules | INFO - Sparsifying model.layers.19.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:06:24.466028+0000 | compress | METRIC - time 1.51s\n",
      "2026-01-27T04:06:24.466902+0000 | compress | METRIC - error 3277.87\n",
      "2026-01-27T04:06:24.467608+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:06:24.467836+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(20/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.71it/s]\n",
      "(21/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:06:38.338266+0000 | compress_modules | INFO - Sparsifying model.layers.20.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:06:38.856830+0000 | compress | METRIC - time 0.52s\n",
      "2026-01-27T04:06:38.857433+0000 | compress | METRIC - error 55810.19\n",
      "2026-01-27T04:06:38.857880+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:38.858120+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:06:38.858516+0000 | compress_modules | INFO - Sparsifying model.layers.20.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:06:39.357497+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:06:39.357869+0000 | compress | METRIC - error 26962.54\n",
      "2026-01-27T04:06:39.358259+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:39.358562+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:06:39.358895+0000 | compress_modules | INFO - Sparsifying model.layers.20.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:06:39.866654+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:06:39.867022+0000 | compress | METRIC - error 8343.85\n",
      "2026-01-27T04:06:39.867439+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:39.867724+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:06:39.868115+0000 | compress_modules | INFO - Sparsifying model.layers.20.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:06:40.383250+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:06:40.383702+0000 | compress | METRIC - error 856.49\n",
      "2026-01-27T04:06:40.384096+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:40.384329+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:06:40.384733+0000 | compress_modules | INFO - Sparsifying model.layers.20.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:06:40.889696+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:06:40.890056+0000 | compress | METRIC - error 73955.84\n",
      "2026-01-27T04:06:40.890478+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:40.890731+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:06:40.891127+0000 | compress_modules | INFO - Sparsifying model.layers.20.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:06:41.388979+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:06:41.389338+0000 | compress | METRIC - error 59938.55\n",
      "2026-01-27T04:06:41.389724+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:41.390029+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:06:41.390405+0000 | compress_modules | INFO - Sparsifying model.layers.20.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:06:42.836507+0000 | compress | METRIC - time 1.45s\n",
      "2026-01-27T04:06:42.837367+0000 | compress | METRIC - error 3136.45\n",
      "2026-01-27T04:06:42.837873+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:06:42.838137+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(21/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.47it/s]\n",
      "(22/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:06:56.713116+0000 | compress_modules | INFO - Sparsifying model.layers.21.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:06:57.217709+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:06:57.218116+0000 | compress | METRIC - error 51837.38\n",
      "2026-01-27T04:06:57.218664+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:57.218936+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:06:57.219348+0000 | compress_modules | INFO - Sparsifying model.layers.21.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:06:57.754713+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:06:57.755100+0000 | compress | METRIC - error 23489.02\n",
      "2026-01-27T04:06:57.755575+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:57.755832+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:06:57.756299+0000 | compress_modules | INFO - Sparsifying model.layers.21.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:06:58.300336+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:06:58.300743+0000 | compress | METRIC - error 9595.68\n",
      "2026-01-27T04:06:58.301170+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:58.301417+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:06:58.301768+0000 | compress_modules | INFO - Sparsifying model.layers.21.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:06:58.857915+0000 | compress | METRIC - time 0.56s\n",
      "2026-01-27T04:06:58.858508+0000 | compress | METRIC - error 1065.51\n",
      "2026-01-27T04:06:58.858938+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:58.859202+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:06:58.859702+0000 | compress_modules | INFO - Sparsifying model.layers.21.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:06:59.380992+0000 | compress | METRIC - time 0.52s\n",
      "2026-01-27T04:06:59.381390+0000 | compress | METRIC - error 76839.11\n",
      "2026-01-27T04:06:59.381788+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:59.382017+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:06:59.382439+0000 | compress_modules | INFO - Sparsifying model.layers.21.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:06:59.881428+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:06:59.881786+0000 | compress | METRIC - error 62022.61\n",
      "2026-01-27T04:06:59.882168+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:06:59.882395+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:06:59.882782+0000 | compress_modules | INFO - Sparsifying model.layers.21.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:07:01.397892+0000 | compress | METRIC - time 1.51s\n",
      "2026-01-27T04:07:01.398841+0000 | compress | METRIC - error 3094.17\n",
      "2026-01-27T04:07:01.399326+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:07:01.399680+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(22/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.54it/s]\n",
      "(23/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:07:15.275606+0000 | compress_modules | INFO - Sparsifying model.layers.22.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:07:15.774354+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:07:15.774770+0000 | compress | METRIC - error 51929.73\n",
      "2026-01-27T04:07:15.775161+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:07:15.775397+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:07:15.775664+0000 | compress_modules | INFO - Sparsifying model.layers.22.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:07:16.270930+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:07:16.271321+0000 | compress | METRIC - error 23687.18\n",
      "2026-01-27T04:07:16.271719+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:07:16.271944+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:07:16.272310+0000 | compress_modules | INFO - Sparsifying model.layers.22.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:07:16.778000+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:07:16.778403+0000 | compress | METRIC - error 10136.41\n",
      "2026-01-27T04:07:16.778787+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:07:16.779008+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:07:16.779382+0000 | compress_modules | INFO - Sparsifying model.layers.22.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:07:17.272100+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:07:17.272498+0000 | compress | METRIC - error 951.41\n",
      "2026-01-27T04:07:17.272914+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:07:17.273146+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:07:17.273428+0000 | compress_modules | INFO - Sparsifying model.layers.22.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:07:17.788691+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:07:17.789031+0000 | compress | METRIC - error 81336.91\n",
      "2026-01-27T04:07:17.789451+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:07:17.789688+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:07:17.790096+0000 | compress_modules | INFO - Sparsifying model.layers.22.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:07:18.306271+0000 | compress | METRIC - time 0.52s\n",
      "2026-01-27T04:07:18.306616+0000 | compress | METRIC - error 65060.86\n",
      "2026-01-27T04:07:18.307033+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:07:18.307356+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:07:18.307698+0000 | compress_modules | INFO - Sparsifying model.layers.22.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:07:19.750519+0000 | compress | METRIC - time 1.44s\n",
      "2026-01-27T04:07:19.751443+0000 | compress | METRIC - error 3296.28\n",
      "2026-01-27T04:07:19.751879+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:07:19.752124+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(23/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.20it/s]\n",
      "(24/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:07:33.625699+0000 | compress_modules | INFO - Sparsifying model.layers.23.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:07:34.124371+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:07:34.124783+0000 | compress | METRIC - error 48712.86\n",
      "2026-01-27T04:07:34.125180+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:07:34.125440+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:07:34.125728+0000 | compress_modules | INFO - Sparsifying model.layers.23.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:07:34.617034+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:07:34.617411+0000 | compress | METRIC - error 23779.81\n",
      "2026-01-27T04:07:34.617771+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:07:34.617982+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:07:34.618322+0000 | compress_modules | INFO - Sparsifying model.layers.23.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:07:35.106558+0000 | compress | METRIC - time 0.49s\n",
      "2026-01-27T04:07:35.107106+0000 | compress | METRIC - error 9964.56\n",
      "2026-01-27T04:07:35.107470+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:07:35.107710+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:07:35.108088+0000 | compress_modules | INFO - Sparsifying model.layers.23.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:07:35.647250+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:07:35.647645+0000 | compress | METRIC - error 1322.71\n",
      "2026-01-27T04:07:35.648046+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:07:35.648254+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:07:35.648613+0000 | compress_modules | INFO - Sparsifying model.layers.23.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:07:36.191244+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:07:36.191647+0000 | compress | METRIC - error 91385.36\n",
      "2026-01-27T04:07:36.192048+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:07:36.192260+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:07:36.192683+0000 | compress_modules | INFO - Sparsifying model.layers.23.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:07:36.737061+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:07:36.737638+0000 | compress | METRIC - error 70484.80\n",
      "2026-01-27T04:07:36.738087+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:07:36.738459+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:07:36.738905+0000 | compress_modules | INFO - Sparsifying model.layers.23.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:07:38.249302+0000 | compress | METRIC - time 1.51s\n",
      "2026-01-27T04:07:38.250141+0000 | compress | METRIC - error 3812.93\n",
      "2026-01-27T04:07:38.250644+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:07:38.250904+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(24/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.40it/s]\n",
      "(25/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:07:52.137606+0000 | compress_modules | INFO - Sparsifying model.layers.24.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:07:52.638516+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:07:52.639100+0000 | compress | METRIC - error 53005.10\n",
      "2026-01-27T04:07:52.639529+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:07:52.639758+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:07:52.640223+0000 | compress_modules | INFO - Sparsifying model.layers.24.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:07:53.143271+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:07:53.143659+0000 | compress | METRIC - error 24964.37\n",
      "2026-01-27T04:07:53.144071+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:07:53.144377+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:07:53.144762+0000 | compress_modules | INFO - Sparsifying model.layers.24.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:07:53.650135+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:07:53.650564+0000 | compress | METRIC - error 12479.29\n",
      "2026-01-27T04:07:53.650980+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:07:53.651218+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:07:53.651501+0000 | compress_modules | INFO - Sparsifying model.layers.24.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:07:54.160029+0000 | compress | METRIC - time 0.51s\n",
      "2026-01-27T04:07:54.160382+0000 | compress | METRIC - error 2167.18\n",
      "2026-01-27T04:07:54.160794+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:07:54.161022+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:07:54.161471+0000 | compress_modules | INFO - Sparsifying model.layers.24.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:07:54.677795+0000 | compress | METRIC - time 0.52s\n",
      "2026-01-27T04:07:54.678127+0000 | compress | METRIC - error 106850.52\n",
      "2026-01-27T04:07:54.678541+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:07:54.678779+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:07:54.679178+0000 | compress_modules | INFO - Sparsifying model.layers.24.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:07:55.198834+0000 | compress | METRIC - time 0.52s\n",
      "2026-01-27T04:07:55.199569+0000 | compress | METRIC - error 80273.64\n",
      "2026-01-27T04:07:55.200008+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:07:55.200214+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:07:55.200564+0000 | compress_modules | INFO - Sparsifying model.layers.24.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:07:56.711717+0000 | compress | METRIC - time 1.51s\n",
      "2026-01-27T04:07:56.712573+0000 | compress | METRIC - error 4648.36\n",
      "2026-01-27T04:07:56.713049+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:07:56.713391+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(25/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.91it/s]\n",
      "(26/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:08:10.592539+0000 | compress_modules | INFO - Sparsifying model.layers.25.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:08:11.138862+0000 | compress | METRIC - time 0.55s\n",
      "2026-01-27T04:08:11.139429+0000 | compress | METRIC - error 56182.84\n",
      "2026-01-27T04:08:11.139903+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:08:11.140163+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:08:11.140641+0000 | compress_modules | INFO - Sparsifying model.layers.25.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:08:11.676765+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:08:11.677305+0000 | compress | METRIC - error 26976.75\n",
      "2026-01-27T04:08:11.677779+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:08:11.678043+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:08:11.678519+0000 | compress_modules | INFO - Sparsifying model.layers.25.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:08:12.212412+0000 | compress | METRIC - time 0.53s\n",
      "2026-01-27T04:08:12.212780+0000 | compress | METRIC - error 14084.59\n",
      "2026-01-27T04:08:12.213249+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:08:12.213511+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:08:12.213972+0000 | compress_modules | INFO - Sparsifying model.layers.25.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:08:12.752821+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:08:12.753215+0000 | compress | METRIC - error 1785.42\n",
      "2026-01-27T04:08:12.753684+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:08:12.753939+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:08:12.754393+0000 | compress_modules | INFO - Sparsifying model.layers.25.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:08:13.255219+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:08:13.255631+0000 | compress | METRIC - error 111079.25\n",
      "2026-01-27T04:08:13.256055+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:08:13.256287+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:08:13.256708+0000 | compress_modules | INFO - Sparsifying model.layers.25.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:08:13.753513+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:08:13.753984+0000 | compress | METRIC - error 85396.83\n",
      "2026-01-27T04:08:13.754458+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:08:13.754694+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:08:13.755116+0000 | compress_modules | INFO - Sparsifying model.layers.25.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:08:15.149231+0000 | compress | METRIC - time 1.39s\n",
      "2026-01-27T04:08:15.150143+0000 | compress | METRIC - error 5696.60\n",
      "2026-01-27T04:08:15.150602+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:08:15.150846+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(26/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.74it/s]\n",
      "(27/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:08:29.032776+0000 | compress_modules | INFO - Sparsifying model.layers.26.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:08:29.577344+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:08:29.577814+0000 | compress | METRIC - error 43728.55\n",
      "2026-01-27T04:08:29.578320+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:08:29.578581+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:08:29.579009+0000 | compress_modules | INFO - Sparsifying model.layers.26.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:08:30.115919+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:08:30.116455+0000 | compress | METRIC - error 17423.58\n",
      "2026-01-27T04:08:30.116900+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:08:30.117147+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:08:30.117587+0000 | compress_modules | INFO - Sparsifying model.layers.26.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:08:30.654048+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:08:30.654462+0000 | compress | METRIC - error 14805.46\n",
      "2026-01-27T04:08:30.654900+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:08:30.655159+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:08:30.655589+0000 | compress_modules | INFO - Sparsifying model.layers.26.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:08:31.188782+0000 | compress | METRIC - time 0.53s\n",
      "2026-01-27T04:08:31.189153+0000 | compress | METRIC - error 3642.06\n",
      "2026-01-27T04:08:31.189592+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:08:31.189859+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:08:31.190263+0000 | compress_modules | INFO - Sparsifying model.layers.26.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:08:31.733340+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:08:31.733728+0000 | compress | METRIC - error 117969.94\n",
      "2026-01-27T04:08:31.734137+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:08:31.734335+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:08:31.734715+0000 | compress_modules | INFO - Sparsifying model.layers.26.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:08:32.279590+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:08:32.280238+0000 | compress | METRIC - error 89918.77\n",
      "2026-01-27T04:08:32.280737+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:08:32.280983+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:08:32.281425+0000 | compress_modules | INFO - Sparsifying model.layers.26.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:08:33.722237+0000 | compress | METRIC - time 1.44s\n",
      "2026-01-27T04:08:33.723131+0000 | compress | METRIC - error 7067.13\n",
      "2026-01-27T04:08:33.723603+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:08:33.723858+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(27/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.61it/s]\n",
      "(28/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 47.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:08:47.646967+0000 | compress_modules | INFO - Sparsifying model.layers.27.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:08:48.163531+0000 | compress | METRIC - time 0.52s\n",
      "2026-01-27T04:08:48.163936+0000 | compress | METRIC - error 40378.31\n",
      "2026-01-27T04:08:48.164476+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:08:48.164760+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:08:48.165191+0000 | compress_modules | INFO - Sparsifying model.layers.27.self_attn.k_proj using 512 samples\n",
      "2026-01-27T04:08:48.712551+0000 | compress | METRIC - time 0.55s\n",
      "2026-01-27T04:08:48.713099+0000 | compress | METRIC - error 16801.38\n",
      "2026-01-27T04:08:48.713705+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:08:48.713929+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:08:48.714447+0000 | compress_modules | INFO - Sparsifying model.layers.27.self_attn.v_proj using 512 samples\n",
      "2026-01-27T04:08:49.248569+0000 | compress | METRIC - time 0.53s\n",
      "2026-01-27T04:08:49.248960+0000 | compress | METRIC - error 10428.73\n",
      "2026-01-27T04:08:49.249605+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:08:49.249975+0000 | compress | METRIC - Compressed module size: 6.291456 MB\n",
      "2026-01-27T04:08:49.250349+0000 | compress_modules | INFO - Sparsifying model.layers.27.self_attn.o_proj using 512 samples\n",
      "2026-01-27T04:08:49.786038+0000 | compress | METRIC - time 0.54s\n",
      "2026-01-27T04:08:49.786456+0000 | compress | METRIC - error 7604.76\n",
      "2026-01-27T04:08:49.786962+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:08:49.787180+0000 | compress | METRIC - Compressed module size: 18.874368 MB\n",
      "2026-01-27T04:08:49.787605+0000 | compress_modules | INFO - Sparsifying model.layers.27.mlp.gate_proj using 512 samples\n",
      "2026-01-27T04:08:50.316864+0000 | compress | METRIC - time 0.53s\n",
      "2026-01-27T04:08:50.317205+0000 | compress | METRIC - error 107708.53\n",
      "2026-01-27T04:08:50.317623+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:08:50.317850+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:08:50.318254+0000 | compress_modules | INFO - Sparsifying model.layers.27.mlp.up_proj using 512 samples\n",
      "2026-01-27T04:08:50.814648+0000 | compress | METRIC - time 0.50s\n",
      "2026-01-27T04:08:50.815056+0000 | compress | METRIC - error 92275.24\n",
      "2026-01-27T04:08:50.815519+0000 | compress | METRIC - GPU 0 | usage: 12.24% | total memory: 25 GB\n",
      "2026-01-27T04:08:50.815804+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n",
      "2026-01-27T04:08:50.816197+0000 | compress_modules | INFO - Sparsifying model.layers.27.mlp.down_proj using 512 samples\n",
      "2026-01-27T04:08:52.206746+0000 | compress | METRIC - time 1.39s\n",
      "2026-01-27T04:08:52.207596+0000 | compress | METRIC - error 14059.75\n",
      "2026-01-27T04:08:52.208023+0000 | compress | METRIC - GPU 0 | usage: 13.28% | total memory: 25 GB\n",
      "2026-01-27T04:08:52.208339+0000 | compress | METRIC - Compressed module size: 50.331648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(28/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.88it/s]\n",
      "(29/29): Calibrating: 100%|██████████| 512/512 [00:00<00:00, 1273.08it/s]\n",
      "(29/29): Propagating: 100%|██████████| 512/512 [00:00<00:00, 1429.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:08:56.072025+0000 | finalize | INFO - Compression lifecycle finalized for 1 modifiers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating model sparsity: 100%|██████████| 255/255 [00:02<00:00, 91.25it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-27T04:08:58.902434+0000 | is_sparse24_bitmask_supported | WARNING - Compressed Sparse-only 2:4 models are not supported in vLLM<=0.7.0, consider saving with `disable_sparse_compression` set, `model.save_pretrained(..., disable_sparse_compression=True)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Compressing model: 196it [00:06, 29.52it/s]\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== SAMPLE GENERATION ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Linear' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     28\u001b[39m dispatch_for_generation(model)\n\u001b[32m     29\u001b[39m input_ids = tokenizer(\u001b[33m\"\u001b[39m\u001b[33mHello my name is\u001b[39m\u001b[33m\"\u001b[39m, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).input_ids.to(\n\u001b[32m     30\u001b[39m     model.device\n\u001b[32m     31\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(tokenizer.decode(output[\u001b[32m0\u001b[39m]))\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m==========================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:2564\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2561\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2563\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2564\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2565\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2566\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2576\u001b[39m     generation_config.return_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2577\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2578\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result.past_key_values, \u001b[33m\"\u001b[39m\u001b[33mto_legacy_cache\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2579\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:2784\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2781\u001b[39m model_inputs = \u001b[38;5;28mself\u001b[39m.prepare_inputs_for_generation(input_ids, **model_kwargs)\n\u001b[32m   2783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[32m-> \u001b[39m\u001b[32m2784\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2785\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2786\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/transformers/utils/generic.py:918\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    920\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:459\u001b[39m, in \u001b[36mLlamaForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    440\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    441\u001b[39m ) -> CausalLMOutputWithPast:\n\u001b[32m    442\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    443\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m    444\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    457\u001b[39m \u001b[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[33;03m    ```\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m     hidden_states = outputs.last_hidden_state\n\u001b[32m    471\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/transformers/utils/generic.py:1072\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapped_fn.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1069\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m     outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1074\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1075\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1076\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1077\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:395\u001b[39m, in \u001b[36mLlamaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, cache_position, use_cache, **kwargs)\u001b[39m\n\u001b[32m    392\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.rotary_emb(hidden_states, position_ids)\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     hidden_states = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[32m    407\u001b[39m     last_hidden_state=hidden_states,\n\u001b[32m    408\u001b[39m     past_key_values=past_key_values,\n\u001b[32m    409\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:294\u001b[39m, in \u001b[36mLlamaDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    292\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    293\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m hidden_states, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    304\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    306\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:236\u001b[39m, in \u001b[36mLlamaAttention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[39m\n\u001b[32m    233\u001b[39m input_shape = hidden_states.shape[:-\u001b[32m1\u001b[39m]\n\u001b[32m    234\u001b[39m hidden_shape = (*input_shape, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.head_dim)\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m query_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mq_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m.view(hidden_shape).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    237\u001b[39m key_states = \u001b[38;5;28mself\u001b[39m.k_proj(hidden_states).view(hidden_shape).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    238\u001b[39m value_states = \u001b[38;5;28mself\u001b[39m.v_proj(hidden_states).view(hidden_shape).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.linear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m, \u001b[38;5;28mself\u001b[39m.bias)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1964\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1963\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1965\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1966\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'Linear' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_ID, dtype='auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "# Load and preprocess dataset\n",
    "ds = load_dataset(\n",
    "    DATASET_ID, \n",
    "    split=f\"{DATASET_SPLIT}[:{NUM_CALIBRATION_SAMPLES}]\"\n",
    ").shuffle(seed=47)\n",
    "ds = ds.map(preprocess)\n",
    "ds = ds.map(tokenize, remove_columns=ds.column_names)\n",
    "\n",
    "# Get compression recipe and save directory\n",
    "recipe, save_dir = get_recipe(QUANT_ENABLE)\n",
    "\n",
    "# Apply compression\n",
    "oneshot(\n",
    "    model=model,\n",
    "    dataset=ds,\n",
    "    recipe=recipe,\n",
    "    max_seq_length=MAX_SEQUENCE_LENGTH,\n",
    "    num_calibration_samples=NUM_CALIBRATION_SAMPLES,\n",
    "    output_dir = save_dir\n",
    ")\n",
    "\n",
    "# Validate the compressed model\n",
    "print(\"\\n========== SAMPLE GENERATION ==============\")\n",
    "dispatch_for_generation(model)\n",
    "input_ids = tokenizer(\"Hello my name is\", return_tensors=\"pt\").input_ids.to(\n",
    "    model.device\n",
    ")\n",
    "output = model.generate(input_ids, max_new_tokens=100)\n",
    "print(tokenizer.decode(output[0]))\n",
    "print(\"==========================================\\n\")\n",
    "\n",
    "# # Save compressed model and tokenizer\n",
    "# model.save_pretrained(save_dir)\n",
    "# tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79dd970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference pruned model via vLLM\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "\n",
    "model_path = r\"Llama-3.2-3B-Instruct2of4-sparse\"\n",
    "\n",
    "model = LLM(\n",
    "    model=model_path,    \n",
    "    gpu_memory_utilization=0.7, # GPU 메모리 70% 사용 (필요시 조절)\n",
    "    tensor_parallel_size=1,   # GPU 1개 사용\n",
    "    enforce_eager=True,      # 호환성 모드 켜기 (필요시)\n",
    "    dtype='auto'\n",
    ")\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.8,\n",
    "    top_p=0.95,\n",
    "    max_tokens=256\n",
    "    )\n",
    "\n",
    "prompt = \"Hello, My name is:\"\n",
    "\n",
    "outputs = model.generate(prompt, sampling_params)\n",
    "\n",
    "for output in outputs:\n",
    "    print(output.outputs[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
